2018-09-12 17:47:49 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['hand', 'Finger1', 'Finger2', 'Joystick'],
 'batch_size': 1,
 'crop': False,
 'crop_pad': 0,
 'dataset': '../../UnaugmentedDataSet_reachingJan30/reaching_Mackenzie95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 10,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': '../../pretrained/resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1000,
 'mean_pixel': [123.68, 116.779, 103.939],
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'regularize': False,
 'save_iters': 50,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.5,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': './snapshot',
 'stride': 8.0,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2018-09-12 17:47:56 Restoring parameters from ../../pretrained/resnet_v1_50.ckpt
2018-09-12 17:47:58 iteration: 0 loss: 0.0844 lr: 0.005
2018-09-12 17:48:24 iteration: 10 loss: 0.2026 lr: 0.005
2018-09-12 17:48:57 iteration: 20 loss: 0.0498 lr: 0.005
2018-09-12 17:49:20 iteration: 30 loss: 0.0370 lr: 0.005
2018-09-12 17:49:42 iteration: 40 loss: 0.0311 lr: 0.005
2018-09-12 17:50:08 iteration: 50 loss: 0.0324 lr: 0.005
2018-09-12 17:50:45 iteration: 60 loss: 0.0363 lr: 0.005
2018-09-12 17:51:08 iteration: 70 loss: 0.0282 lr: 0.005
2018-09-12 17:51:43 iteration: 80 loss: 0.0292 lr: 0.005
2018-09-12 17:52:00 iteration: 90 loss: 0.0238 lr: 0.005
2018-09-12 17:52:27 iteration: 100 loss: 0.0237 lr: 0.005
2018-09-12 17:52:55 iteration: 110 loss: 0.0257 lr: 0.005
2018-09-12 17:53:28 iteration: 120 loss: 0.0320 lr: 0.005
2018-09-12 17:53:54 iteration: 130 loss: 0.0247 lr: 0.005
2018-09-12 17:54:23 iteration: 140 loss: 0.0249 lr: 0.005
2018-09-12 17:55:05 iteration: 150 loss: 0.0236 lr: 0.005
2018-09-12 17:55:50 iteration: 160 loss: 0.0215 lr: 0.005
2018-09-12 17:56:42 iteration: 170 loss: 0.0300 lr: 0.005
2018-09-12 17:57:26 iteration: 180 loss: 0.0248 lr: 0.005
2018-09-12 17:57:55 iteration: 190 loss: 0.0211 lr: 0.005
2018-09-12 17:58:27 iteration: 200 loss: 0.0221 lr: 0.005
2018-09-12 17:59:01 iteration: 210 loss: 0.0176 lr: 0.005
2018-09-12 17:59:45 iteration: 220 loss: 0.0250 lr: 0.005
2018-09-12 18:00:14 iteration: 230 loss: 0.0200 lr: 0.005
2018-09-12 18:00:51 iteration: 240 loss: 0.0228 lr: 0.005
2018-09-12 18:01:29 iteration: 250 loss: 0.0230 lr: 0.005
2018-09-12 18:01:53 iteration: 260 loss: 0.0177 lr: 0.005
2018-09-12 18:02:22 iteration: 270 loss: 0.0205 lr: 0.005
2018-09-12 18:02:52 iteration: 280 loss: 0.0221 lr: 0.005
2018-09-12 18:03:21 iteration: 290 loss: 0.0178 lr: 0.005
2018-09-12 18:03:54 iteration: 300 loss: 0.0215 lr: 0.005
2018-09-12 18:04:25 iteration: 310 loss: 0.0200 lr: 0.005
2018-09-12 18:04:47 iteration: 320 loss: 0.0164 lr: 0.005
2018-09-12 18:05:20 iteration: 330 loss: 0.0228 lr: 0.005
2018-09-12 18:05:56 iteration: 340 loss: 0.0184 lr: 0.005
2018-09-12 18:06:22 iteration: 350 loss: 0.0167 lr: 0.005
2018-09-12 18:06:50 iteration: 360 loss: 0.0186 lr: 0.005
2018-09-12 18:07:18 iteration: 370 loss: 0.0157 lr: 0.005
2018-09-12 18:07:50 iteration: 380 loss: 0.0188 lr: 0.005
2018-09-12 18:08:18 iteration: 390 loss: 0.0163 lr: 0.005
2018-09-12 18:08:42 iteration: 400 loss: 0.0150 lr: 0.005
2018-09-12 18:09:14 iteration: 410 loss: 0.0174 lr: 0.005
2018-09-12 18:09:42 iteration: 420 loss: 0.0148 lr: 0.005
2018-09-12 18:10:11 iteration: 430 loss: 0.0160 lr: 0.005
2018-09-12 18:10:32 iteration: 440 loss: 0.0136 lr: 0.005
2018-09-12 18:10:58 iteration: 450 loss: 0.0137 lr: 0.005
2018-09-12 18:11:22 iteration: 460 loss: 0.0129 lr: 0.005
2018-09-12 18:11:55 iteration: 470 loss: 0.0157 lr: 0.005
2018-09-12 18:12:26 iteration: 480 loss: 0.0157 lr: 0.005
2018-09-12 18:12:51 iteration: 490 loss: 0.0136 lr: 0.005
2018-09-12 18:13:20 iteration: 500 loss: 0.0149 lr: 0.005
2018-09-12 18:13:48 iteration: 510 loss: 0.0131 lr: 0.005
2018-09-12 18:14:27 iteration: 520 loss: 0.0164 lr: 0.005
2018-09-12 18:14:51 iteration: 530 loss: 0.0126 lr: 0.005
2018-09-12 18:15:21 iteration: 540 loss: 0.0135 lr: 0.005
2018-09-12 18:15:54 iteration: 550 loss: 0.0162 lr: 0.005
2018-09-12 18:16:23 iteration: 560 loss: 0.0142 lr: 0.005
2018-09-12 18:16:49 iteration: 570 loss: 0.0133 lr: 0.005
2018-09-12 18:17:23 iteration: 580 loss: 0.0133 lr: 0.005
2018-09-12 18:17:44 iteration: 590 loss: 0.0134 lr: 0.005
2018-09-12 18:18:13 iteration: 600 loss: 0.0124 lr: 0.005
2018-09-12 18:18:40 iteration: 610 loss: 0.0129 lr: 0.005
2018-09-12 18:18:59 iteration: 620 loss: 0.0122 lr: 0.005
2018-09-12 18:19:32 iteration: 630 loss: 0.0128 lr: 0.005
2018-09-12 18:19:55 iteration: 640 loss: 0.0103 lr: 0.005
2018-09-12 18:20:21 iteration: 650 loss: 0.0103 lr: 0.005
2018-09-12 18:20:55 iteration: 660 loss: 0.0133 lr: 0.005
2018-09-12 18:21:26 iteration: 670 loss: 0.0125 lr: 0.005
2018-09-12 18:21:50 iteration: 680 loss: 0.0120 lr: 0.005
2018-09-12 18:22:16 iteration: 690 loss: 0.0144 lr: 0.005
2018-09-12 18:22:37 iteration: 700 loss: 0.0107 lr: 0.005
2018-09-12 18:22:58 iteration: 710 loss: 0.0102 lr: 0.005
2018-09-12 18:23:25 iteration: 720 loss: 0.0136 lr: 0.005
2018-09-12 18:23:50 iteration: 730 loss: 0.0108 lr: 0.005
2018-09-12 18:24:21 iteration: 740 loss: 0.0123 lr: 0.005
2018-09-12 18:24:51 iteration: 750 loss: 0.0114 lr: 0.005
2018-09-12 18:25:24 iteration: 760 loss: 0.0131 lr: 0.005
2018-09-12 18:25:52 iteration: 770 loss: 0.0117 lr: 0.005
2018-09-12 18:26:21 iteration: 780 loss: 0.0106 lr: 0.005
2018-09-12 18:26:51 iteration: 790 loss: 0.0105 lr: 0.005
2018-09-12 18:27:10 iteration: 800 loss: 0.0096 lr: 0.005
2018-09-12 18:27:33 iteration: 810 loss: 0.0103 lr: 0.005
2018-09-12 18:27:57 iteration: 820 loss: 0.0087 lr: 0.005
2018-09-12 18:28:24 iteration: 830 loss: 0.0107 lr: 0.005
2018-09-12 18:28:59 iteration: 840 loss: 0.0115 lr: 0.005
2018-09-12 18:29:26 iteration: 850 loss: 0.0099 lr: 0.005
2018-09-12 18:29:46 iteration: 860 loss: 0.0087 lr: 0.005
2018-09-12 18:30:04 iteration: 870 loss: 0.0088 lr: 0.005
2018-09-12 18:30:34 iteration: 880 loss: 0.0113 lr: 0.005
2018-09-12 18:31:00 iteration: 890 loss: 0.0109 lr: 0.005
2018-09-12 18:31:29 iteration: 900 loss: 0.0096 lr: 0.005
2018-09-12 18:31:55 iteration: 910 loss: 0.0102 lr: 0.005
2018-09-12 18:32:23 iteration: 920 loss: 0.0094 lr: 0.005
2018-09-12 18:32:48 iteration: 930 loss: 0.0096 lr: 0.005
2018-09-12 18:33:14 iteration: 940 loss: 0.0097 lr: 0.005
2018-09-12 18:33:42 iteration: 950 loss: 0.0102 lr: 0.005
2018-09-12 18:34:13 iteration: 960 loss: 0.0111 lr: 0.005
2018-09-12 18:34:46 iteration: 970 loss: 0.0121 lr: 0.005
2018-09-12 18:35:18 iteration: 980 loss: 0.0101 lr: 0.005
2018-09-12 18:35:46 iteration: 990 loss: 0.0097 lr: 0.005
2018-09-12 18:36:21 iteration: 1000 loss: 0.0110 lr: 0.005
2018-09-12 18:36:48 iteration: 1010 loss: 0.0135 lr: 0.005
2018-09-12 18:37:14 iteration: 1020 loss: 0.0097 lr: 0.005
2018-09-12 18:37:40 iteration: 1030 loss: 0.0122 lr: 0.005
2018-09-12 18:38:06 iteration: 1040 loss: 0.0104 lr: 0.005
2018-09-12 18:38:42 iteration: 1050 loss: 0.0118 lr: 0.005
2018-09-12 18:39:08 iteration: 1060 loss: 0.0082 lr: 0.005
2018-09-12 18:39:34 iteration: 1070 loss: 0.0100 lr: 0.005
2018-09-12 18:39:54 iteration: 1080 loss: 0.0082 lr: 0.005
2018-09-12 18:40:21 iteration: 1090 loss: 0.0093 lr: 0.005
2018-09-12 18:40:53 iteration: 1100 loss: 0.0093 lr: 0.005
2018-09-12 18:41:18 iteration: 1110 loss: 0.0098 lr: 0.005
2018-09-12 18:41:48 iteration: 1120 loss: 0.0089 lr: 0.005
2018-09-12 18:42:10 iteration: 1130 loss: 0.0084 lr: 0.005
2018-09-12 18:42:34 iteration: 1140 loss: 0.0098 lr: 0.005
2018-09-12 18:42:53 iteration: 1150 loss: 0.0087 lr: 0.005
2018-09-12 18:43:25 iteration: 1160 loss: 0.0094 lr: 0.005
2018-09-12 18:43:52 iteration: 1170 loss: 0.0088 lr: 0.005
2018-09-12 18:44:21 iteration: 1180 loss: 0.0089 lr: 0.005
2018-09-12 18:44:55 iteration: 1190 loss: 0.0088 lr: 0.005
2018-09-12 18:45:26 iteration: 1200 loss: 0.0087 lr: 0.005
2018-09-12 18:46:01 iteration: 1210 loss: 0.0090 lr: 0.005
2018-09-12 18:46:27 iteration: 1220 loss: 0.0079 lr: 0.005
2018-09-12 18:46:54 iteration: 1230 loss: 0.0089 lr: 0.005
2018-09-12 18:47:17 iteration: 1240 loss: 0.0100 lr: 0.005
2018-09-12 18:47:42 iteration: 1250 loss: 0.0090 lr: 0.005
2018-09-12 18:48:11 iteration: 1260 loss: 0.0093 lr: 0.005
2018-09-12 18:48:43 iteration: 1270 loss: 0.0092 lr: 0.005
2018-09-12 18:49:12 iteration: 1280 loss: 0.0101 lr: 0.005
2018-09-12 18:49:35 iteration: 1290 loss: 0.0098 lr: 0.005
2018-09-12 18:50:03 iteration: 1300 loss: 0.0099 lr: 0.005
2018-09-12 18:50:30 iteration: 1310 loss: 0.0095 lr: 0.005
2018-09-12 18:50:56 iteration: 1320 loss: 0.0091 lr: 0.005
2018-09-12 18:51:20 iteration: 1330 loss: 0.0081 lr: 0.005
2018-09-12 18:51:48 iteration: 1340 loss: 0.0082 lr: 0.005
2018-09-12 18:52:11 iteration: 1350 loss: 0.0073 lr: 0.005
2018-09-12 18:52:46 iteration: 1360 loss: 0.0085 lr: 0.005
2018-09-12 18:53:08 iteration: 1370 loss: 0.0080 lr: 0.005
2018-09-12 18:53:39 iteration: 1380 loss: 0.0077 lr: 0.005
2018-09-12 18:54:01 iteration: 1390 loss: 0.0082 lr: 0.005
2018-09-12 18:54:35 iteration: 1400 loss: 0.0087 lr: 0.005
2018-09-12 18:54:56 iteration: 1410 loss: 0.0083 lr: 0.005
2018-09-12 18:55:28 iteration: 1420 loss: 0.0082 lr: 0.005
2018-09-12 18:55:54 iteration: 1430 loss: 0.0092 lr: 0.005
2018-09-12 18:56:14 iteration: 1440 loss: 0.0070 lr: 0.005
2018-09-12 18:56:45 iteration: 1450 loss: 0.0083 lr: 0.005
2018-09-12 18:57:15 iteration: 1460 loss: 0.0078 lr: 0.005
2018-09-12 18:57:48 iteration: 1470 loss: 0.0094 lr: 0.005
2018-09-12 18:58:14 iteration: 1480 loss: 0.0078 lr: 0.005
2018-09-12 18:58:40 iteration: 1490 loss: 0.0082 lr: 0.005
2018-09-12 18:59:05 iteration: 1500 loss: 0.0087 lr: 0.005
2018-09-12 18:59:30 iteration: 1510 loss: 0.0082 lr: 0.005
2018-09-12 19:00:03 iteration: 1520 loss: 0.0098 lr: 0.005
2018-09-12 19:00:30 iteration: 1530 loss: 0.0079 lr: 0.005
2018-09-12 19:01:00 iteration: 1540 loss: 0.0082 lr: 0.005
2018-09-12 19:01:33 iteration: 1550 loss: 0.0083 lr: 0.005
2018-09-12 19:02:08 iteration: 1560 loss: 0.0072 lr: 0.005
2018-09-12 19:02:38 iteration: 1570 loss: 0.0080 lr: 0.005
2018-09-12 19:02:57 iteration: 1580 loss: 0.0075 lr: 0.005
2018-09-12 19:03:35 iteration: 1590 loss: 0.0087 lr: 0.005
2018-09-12 19:04:03 iteration: 1600 loss: 0.0075 lr: 0.005
2018-09-12 19:04:31 iteration: 1610 loss: 0.0071 lr: 0.005
2018-09-12 19:04:59 iteration: 1620 loss: 0.0073 lr: 0.005
2018-09-12 19:05:32 iteration: 1630 loss: 0.0069 lr: 0.005
2018-09-12 19:05:57 iteration: 1640 loss: 0.0071 lr: 0.005
2018-09-12 19:06:24 iteration: 1650 loss: 0.0073 lr: 0.005
2018-09-12 19:06:50 iteration: 1660 loss: 0.0076 lr: 0.005
2018-09-12 19:07:12 iteration: 1670 loss: 0.0075 lr: 0.005
2018-09-12 19:07:37 iteration: 1680 loss: 0.0079 lr: 0.005
2018-09-12 19:08:07 iteration: 1690 loss: 0.0070 lr: 0.005
2018-09-12 19:08:32 iteration: 1700 loss: 0.0068 lr: 0.005
2018-09-12 19:08:58 iteration: 1710 loss: 0.0085 lr: 0.005
2018-09-12 19:09:35 iteration: 1720 loss: 0.0095 lr: 0.005
2018-09-12 19:09:59 iteration: 1730 loss: 0.0075 lr: 0.005
2018-09-12 19:10:25 iteration: 1740 loss: 0.0076 lr: 0.005
2018-09-12 19:10:55 iteration: 1750 loss: 0.0066 lr: 0.005
2018-09-12 19:11:27 iteration: 1760 loss: 0.0068 lr: 0.005
2018-09-12 19:11:54 iteration: 1770 loss: 0.0089 lr: 0.005
2018-09-12 19:12:24 iteration: 1780 loss: 0.0067 lr: 0.005
2018-09-12 19:12:55 iteration: 1790 loss: 0.0081 lr: 0.005
2018-09-12 19:13:18 iteration: 1800 loss: 0.0071 lr: 0.005
2018-09-12 19:13:42 iteration: 1810 loss: 0.0068 lr: 0.005
2018-09-12 19:14:08 iteration: 1820 loss: 0.0066 lr: 0.005
2018-09-12 19:14:40 iteration: 1830 loss: 0.0090 lr: 0.005
2018-09-12 19:15:12 iteration: 1840 loss: 0.0077 lr: 0.005
2018-09-12 19:15:44 iteration: 1850 loss: 0.0085 lr: 0.005
2018-09-12 19:16:08 iteration: 1860 loss: 0.0076 lr: 0.005
2018-09-12 19:16:36 iteration: 1870 loss: 0.0083 lr: 0.005
2018-09-12 19:17:04 iteration: 1880 loss: 0.0083 lr: 0.005
2018-09-12 19:17:36 iteration: 1890 loss: 0.0074 lr: 0.005
2018-09-12 19:18:07 iteration: 1900 loss: 0.0088 lr: 0.005
2018-09-12 19:18:35 iteration: 1910 loss: 0.0072 lr: 0.005
2018-09-12 19:19:05 iteration: 1920 loss: 0.0065 lr: 0.005
2018-09-12 19:19:34 iteration: 1930 loss: 0.0070 lr: 0.005
2018-09-12 19:20:03 iteration: 1940 loss: 0.0078 lr: 0.005
2018-09-12 19:20:33 iteration: 1950 loss: 0.0074 lr: 0.005
2018-09-12 19:21:11 iteration: 1960 loss: 0.0072 lr: 0.005
2018-09-12 19:21:41 iteration: 1970 loss: 0.0067 lr: 0.005
2018-09-12 19:22:07 iteration: 1980 loss: 0.0066 lr: 0.005
2018-09-12 19:22:43 iteration: 1990 loss: 0.0073 lr: 0.005
2018-09-12 19:23:04 iteration: 2000 loss: 0.0074 lr: 0.005
2018-09-12 19:23:37 iteration: 2010 loss: 0.0071 lr: 0.005
2018-09-12 19:24:09 iteration: 2020 loss: 0.0064 lr: 0.005
2018-09-12 19:24:42 iteration: 2030 loss: 0.0065 lr: 0.005
2018-09-12 19:25:12 iteration: 2040 loss: 0.0078 lr: 0.005
2018-09-12 19:25:38 iteration: 2050 loss: 0.0063 lr: 0.005
2018-09-12 19:26:00 iteration: 2060 loss: 0.0064 lr: 0.005
2018-09-12 19:26:26 iteration: 2070 loss: 0.0070 lr: 0.005
2018-09-12 19:26:57 iteration: 2080 loss: 0.0062 lr: 0.005
2018-09-12 19:27:27 iteration: 2090 loss: 0.0078 lr: 0.005
2018-09-12 19:27:53 iteration: 2100 loss: 0.0071 lr: 0.005
2018-09-12 19:28:15 iteration: 2110 loss: 0.0061 lr: 0.005
2018-09-12 19:28:44 iteration: 2120 loss: 0.0061 lr: 0.005
2018-09-12 19:29:12 iteration: 2130 loss: 0.0084 lr: 0.005
2018-09-12 19:29:43 iteration: 2140 loss: 0.0078 lr: 0.005
2018-09-12 19:30:14 iteration: 2150 loss: 0.0082 lr: 0.005
2018-09-12 19:30:52 iteration: 2160 loss: 0.0067 lr: 0.005
2018-09-12 19:31:24 iteration: 2170 loss: 0.0078 lr: 0.005
2018-09-12 19:31:49 iteration: 2180 loss: 0.0081 lr: 0.005
2018-09-12 19:32:16 iteration: 2190 loss: 0.0069 lr: 0.005
2018-09-12 19:32:34 iteration: 2200 loss: 0.0061 lr: 0.005
2018-09-12 19:33:07 iteration: 2210 loss: 0.0060 lr: 0.005
2018-09-12 19:33:32 iteration: 2220 loss: 0.0063 lr: 0.005
2018-09-12 19:34:02 iteration: 2230 loss: 0.0088 lr: 0.005
2018-09-12 19:34:28 iteration: 2240 loss: 0.0062 lr: 0.005
2018-09-12 19:34:58 iteration: 2250 loss: 0.0072 lr: 0.005
2018-09-12 19:35:30 iteration: 2260 loss: 0.0062 lr: 0.005
2018-09-12 19:35:53 iteration: 2270 loss: 0.0066 lr: 0.005
2018-09-12 19:36:22 iteration: 2280 loss: 0.0058 lr: 0.005
2018-09-12 19:36:53 iteration: 2290 loss: 0.0059 lr: 0.005
2018-09-12 19:37:20 iteration: 2300 loss: 0.0068 lr: 0.005
2018-09-12 19:37:47 iteration: 2310 loss: 0.0070 lr: 0.005
2018-09-12 19:38:14 iteration: 2320 loss: 0.0061 lr: 0.005
2018-09-12 19:38:46 iteration: 2330 loss: 0.0066 lr: 0.005
2018-09-12 19:39:21 iteration: 2340 loss: 0.0062 lr: 0.005
2018-09-12 19:39:48 iteration: 2350 loss: 0.0059 lr: 0.005
2018-09-12 19:40:15 iteration: 2360 loss: 0.0063 lr: 0.005
2018-09-12 19:40:53 iteration: 2370 loss: 0.0063 lr: 0.005
2018-09-12 19:41:16 iteration: 2380 loss: 0.0055 lr: 0.005
2018-09-12 19:41:42 iteration: 2390 loss: 0.0059 lr: 0.005
2018-09-12 19:42:12 iteration: 2400 loss: 0.0064 lr: 0.005
2018-09-12 19:42:42 iteration: 2410 loss: 0.0062 lr: 0.005
2018-09-12 19:43:08 iteration: 2420 loss: 0.0071 lr: 0.005
2018-09-12 19:43:31 iteration: 2430 loss: 0.0064 lr: 0.005
2018-09-12 19:43:53 iteration: 2440 loss: 0.0067 lr: 0.005
2018-09-12 19:44:15 iteration: 2450 loss: 0.0057 lr: 0.005
2018-09-12 19:44:41 iteration: 2460 loss: 0.0060 lr: 0.005
2018-09-12 19:45:06 iteration: 2470 loss: 0.0055 lr: 0.005
2018-09-12 19:45:33 iteration: 2480 loss: 0.0059 lr: 0.005
2018-09-12 19:45:58 iteration: 2490 loss: 0.0064 lr: 0.005
2018-09-12 19:46:28 iteration: 2500 loss: 0.0069 lr: 0.005
2018-09-12 19:46:57 iteration: 2510 loss: 0.0064 lr: 0.005
2018-09-12 19:47:29 iteration: 2520 loss: 0.0064 lr: 0.005
2018-09-12 19:48:03 iteration: 2530 loss: 0.0067 lr: 0.005
2018-09-12 19:48:26 iteration: 2540 loss: 0.0060 lr: 0.005
2018-09-12 19:48:56 iteration: 2550 loss: 0.0070 lr: 0.005
2018-09-12 19:49:28 iteration: 2560 loss: 0.0065 lr: 0.005
2018-09-12 19:50:02 iteration: 2570 loss: 0.0068 lr: 0.005
2018-09-12 19:50:33 iteration: 2580 loss: 0.0060 lr: 0.005
2018-09-12 19:51:05 iteration: 2590 loss: 0.0063 lr: 0.005
2018-09-12 19:51:33 iteration: 2600 loss: 0.0062 lr: 0.005
2018-09-12 19:52:06 iteration: 2610 loss: 0.0059 lr: 0.005
2018-09-12 19:52:45 iteration: 2620 loss: 0.0070 lr: 0.005
2018-09-12 19:53:13 iteration: 2630 loss: 0.0056 lr: 0.005
2018-09-12 19:53:43 iteration: 2640 loss: 0.0059 lr: 0.005
2018-09-12 19:54:17 iteration: 2650 loss: 0.0050 lr: 0.005
2018-09-12 19:54:38 iteration: 2660 loss: 0.0061 lr: 0.005
2018-09-12 19:55:12 iteration: 2670 loss: 0.0061 lr: 0.005
2018-09-12 19:55:37 iteration: 2680 loss: 0.0051 lr: 0.005
2018-09-12 19:55:57 iteration: 2690 loss: 0.0052 lr: 0.005
2018-09-12 19:56:26 iteration: 2700 loss: 0.0059 lr: 0.005
2018-09-12 19:56:58 iteration: 2710 loss: 0.0049 lr: 0.005
2018-09-12 19:57:23 iteration: 2720 loss: 0.0055 lr: 0.005
2018-09-12 19:57:41 iteration: 2730 loss: 0.0061 lr: 0.005
2018-09-12 19:58:09 iteration: 2740 loss: 0.0053 lr: 0.005
2018-09-12 19:58:36 iteration: 2750 loss: 0.0055 lr: 0.005
2018-09-12 19:59:07 iteration: 2760 loss: 0.0059 lr: 0.005
2018-09-12 19:59:25 iteration: 2770 loss: 0.0055 lr: 0.005
2018-09-12 19:59:54 iteration: 2780 loss: 0.0051 lr: 0.005
2018-09-12 20:00:27 iteration: 2790 loss: 0.0057 lr: 0.005
2018-09-12 20:00:51 iteration: 2800 loss: 0.0060 lr: 0.005
2018-09-12 20:01:23 iteration: 2810 loss: 0.0058 lr: 0.005
2018-09-12 20:01:56 iteration: 2820 loss: 0.0049 lr: 0.005
2018-09-12 20:02:27 iteration: 2830 loss: 0.0064 lr: 0.005
2018-09-12 20:02:53 iteration: 2840 loss: 0.0059 lr: 0.005
2018-09-12 20:03:23 iteration: 2850 loss: 0.0051 lr: 0.005
2018-09-12 20:03:47 iteration: 2860 loss: 0.0057 lr: 0.005
2018-09-12 20:04:13 iteration: 2870 loss: 0.0055 lr: 0.005
2018-09-12 20:04:42 iteration: 2880 loss: 0.0058 lr: 0.005
2018-09-12 20:05:06 iteration: 2890 loss: 0.0059 lr: 0.005
2018-09-12 20:05:30 iteration: 2900 loss: 0.0054 lr: 0.005
2018-09-12 20:06:10 iteration: 2910 loss: 0.0063 lr: 0.005
2018-09-12 20:06:37 iteration: 2920 loss: 0.0054 lr: 0.005
2018-09-12 20:07:14 iteration: 2930 loss: 0.0063 lr: 0.005
2018-09-12 20:07:40 iteration: 2940 loss: 0.0067 lr: 0.005
2018-09-12 20:08:11 iteration: 2950 loss: 0.0069 lr: 0.005
2018-09-12 20:08:37 iteration: 2960 loss: 0.0060 lr: 0.005
2018-09-12 20:09:07 iteration: 2970 loss: 0.0054 lr: 0.005
2018-09-12 20:09:35 iteration: 2980 loss: 0.0053 lr: 0.005
2018-09-12 20:10:03 iteration: 2990 loss: 0.0060 lr: 0.005
2018-09-12 20:10:49 iteration: 3000 loss: 0.0056 lr: 0.005
2018-09-12 20:11:17 iteration: 3010 loss: 0.0051 lr: 0.005
2018-09-12 20:11:40 iteration: 3020 loss: 0.0057 lr: 0.005
2018-09-12 20:12:10 iteration: 3030 loss: 0.0056 lr: 0.005
2018-09-12 20:12:35 iteration: 3040 loss: 0.0055 lr: 0.005
2018-09-12 20:13:07 iteration: 3050 loss: 0.0049 lr: 0.005
2018-09-12 20:13:29 iteration: 3060 loss: 0.0051 lr: 0.005
2018-09-12 20:13:54 iteration: 3070 loss: 0.0057 lr: 0.005
2018-09-12 20:14:19 iteration: 3080 loss: 0.0059 lr: 0.005
2018-09-12 20:14:43 iteration: 3090 loss: 0.0060 lr: 0.005
2018-09-12 20:15:09 iteration: 3100 loss: 0.0048 lr: 0.005
2018-09-12 20:15:46 iteration: 3110 loss: 0.0064 lr: 0.005
2018-09-12 20:16:15 iteration: 3120 loss: 0.0055 lr: 0.005
2018-09-12 20:16:45 iteration: 3130 loss: 0.0056 lr: 0.005
2018-09-12 20:17:16 iteration: 3140 loss: 0.0060 lr: 0.005
2018-09-12 20:17:39 iteration: 3150 loss: 0.0059 lr: 0.005
2018-09-12 20:18:05 iteration: 3160 loss: 0.0054 lr: 0.005
2018-09-12 20:18:29 iteration: 3170 loss: 0.0054 lr: 0.005
2018-09-12 20:18:53 iteration: 3180 loss: 0.0056 lr: 0.005
2018-09-12 20:19:14 iteration: 3190 loss: 0.0053 lr: 0.005
2018-09-12 20:19:40 iteration: 3200 loss: 0.0051 lr: 0.005
2018-09-12 20:20:05 iteration: 3210 loss: 0.0050 lr: 0.005
2018-09-12 20:20:33 iteration: 3220 loss: 0.0047 lr: 0.005
2018-09-12 20:20:54 iteration: 3230 loss: 0.0052 lr: 0.005
2018-09-12 20:21:32 iteration: 3240 loss: 0.0057 lr: 0.005
2018-09-12 20:21:58 iteration: 3250 loss: 0.0054 lr: 0.005
2018-09-12 20:22:22 iteration: 3260 loss: 0.0055 lr: 0.005
2018-09-12 20:22:49 iteration: 3270 loss: 0.0054 lr: 0.005
2018-09-12 20:23:18 iteration: 3280 loss: 0.0051 lr: 0.005
2018-09-12 20:23:44 iteration: 3290 loss: 0.0054 lr: 0.005
2018-09-12 20:24:04 iteration: 3300 loss: 0.0054 lr: 0.005
2018-09-12 20:24:39 iteration: 3310 loss: 0.0046 lr: 0.005
2018-09-12 20:25:04 iteration: 3320 loss: 0.0059 lr: 0.005
2018-09-12 20:25:26 iteration: 3330 loss: 0.0059 lr: 0.005
2018-09-12 20:25:54 iteration: 3340 loss: 0.0061 lr: 0.005
2018-09-12 20:26:14 iteration: 3350 loss: 0.0056 lr: 0.005
2018-09-12 20:26:46 iteration: 3360 loss: 0.0048 lr: 0.005
2018-09-12 20:27:13 iteration: 3370 loss: 0.0053 lr: 0.005
2018-09-12 20:27:45 iteration: 3380 loss: 0.0054 lr: 0.005
2018-09-12 20:28:14 iteration: 3390 loss: 0.0054 lr: 0.005
2018-09-12 20:28:39 iteration: 3400 loss: 0.0052 lr: 0.005
2018-09-12 20:29:06 iteration: 3410 loss: 0.0057 lr: 0.005
2018-09-12 20:29:38 iteration: 3420 loss: 0.0052 lr: 0.005
2018-09-12 20:30:09 iteration: 3430 loss: 0.0054 lr: 0.005
2018-09-12 20:30:30 iteration: 3440 loss: 0.0053 lr: 0.005
2018-09-12 20:30:58 iteration: 3450 loss: 0.0048 lr: 0.005
2018-09-12 20:31:27 iteration: 3460 loss: 0.0048 lr: 0.005
2018-09-12 20:31:54 iteration: 3470 loss: 0.0050 lr: 0.005
2018-09-12 20:32:15 iteration: 3480 loss: 0.0050 lr: 0.005
2018-09-12 20:32:40 iteration: 3490 loss: 0.0041 lr: 0.005
2018-09-12 20:33:09 iteration: 3500 loss: 0.0050 lr: 0.005
2018-09-12 20:33:31 iteration: 3510 loss: 0.0051 lr: 0.005
2018-09-12 20:33:54 iteration: 3520 loss: 0.0056 lr: 0.005
2018-09-12 20:34:32 iteration: 3530 loss: 0.0055 lr: 0.005
2018-09-12 20:35:05 iteration: 3540 loss: 0.0045 lr: 0.005
2018-09-12 20:35:27 iteration: 3550 loss: 0.0052 lr: 0.005
2018-09-12 20:35:59 iteration: 3560 loss: 0.0056 lr: 0.005
2018-09-12 20:36:27 iteration: 3570 loss: 0.0053 lr: 0.005
2018-09-12 20:37:02 iteration: 3580 loss: 0.0054 lr: 0.005
2018-09-12 20:37:35 iteration: 3590 loss: 0.0055 lr: 0.005
2018-09-12 20:38:09 iteration: 3600 loss: 0.0045 lr: 0.005
2018-09-12 20:38:38 iteration: 3610 loss: 0.0050 lr: 0.005
2018-09-12 20:39:08 iteration: 3620 loss: 0.0047 lr: 0.005
2018-09-12 20:39:42 iteration: 3630 loss: 0.0048 lr: 0.005
2018-09-12 20:40:07 iteration: 3640 loss: 0.0043 lr: 0.005
2018-09-12 20:40:30 iteration: 3650 loss: 0.0053 lr: 0.005
2018-09-12 20:40:58 iteration: 3660 loss: 0.0050 lr: 0.005
2018-09-12 20:41:31 iteration: 3670 loss: 0.0048 lr: 0.005
2018-09-12 20:41:54 iteration: 3680 loss: 0.0059 lr: 0.005
2018-09-12 20:42:22 iteration: 3690 loss: 0.0052 lr: 0.005
2018-09-12 20:42:57 iteration: 3700 loss: 0.0050 lr: 0.005
2018-09-12 20:43:21 iteration: 3710 loss: 0.0048 lr: 0.005
2018-09-12 20:43:46 iteration: 3720 loss: 0.0050 lr: 0.005
2018-09-12 20:44:06 iteration: 3730 loss: 0.0050 lr: 0.005
2018-09-12 20:44:39 iteration: 3740 loss: 0.0047 lr: 0.005
2018-09-12 20:45:13 iteration: 3750 loss: 0.0047 lr: 0.005
2018-09-12 20:45:38 iteration: 3760 loss: 0.0060 lr: 0.005
2018-09-12 20:46:13 iteration: 3770 loss: 0.0054 lr: 0.005
2018-09-12 20:46:41 iteration: 3780 loss: 0.0052 lr: 0.005
2018-09-12 20:46:59 iteration: 3790 loss: 0.0048 lr: 0.005
2018-09-12 20:47:27 iteration: 3800 loss: 0.0047 lr: 0.005
2018-09-12 20:47:53 iteration: 3810 loss: 0.0048 lr: 0.005
2018-09-12 20:48:23 iteration: 3820 loss: 0.0052 lr: 0.005
2018-09-12 20:48:46 iteration: 3830 loss: 0.0044 lr: 0.005
2018-09-12 20:49:22 iteration: 3840 loss: 0.0044 lr: 0.005
2018-09-12 20:49:55 iteration: 3850 loss: 0.0052 lr: 0.005
2018-09-12 20:50:23 iteration: 3860 loss: 0.0047 lr: 0.005
2018-09-12 20:50:55 iteration: 3870 loss: 0.0042 lr: 0.005
2018-09-12 20:51:18 iteration: 3880 loss: 0.0046 lr: 0.005
2018-09-12 20:51:58 iteration: 3890 loss: 0.0060 lr: 0.005
2018-09-12 20:52:20 iteration: 3900 loss: 0.0057 lr: 0.005
2018-09-12 20:52:45 iteration: 3910 loss: 0.0059 lr: 0.005
2018-09-12 20:53:11 iteration: 3920 loss: 0.0055 lr: 0.005
2018-09-12 20:53:35 iteration: 3930 loss: 0.0043 lr: 0.005
2018-09-12 20:54:11 iteration: 3940 loss: 0.0057 lr: 0.005
2018-09-12 20:54:38 iteration: 3950 loss: 0.0045 lr: 0.005
2018-09-12 20:55:04 iteration: 3960 loss: 0.0051 lr: 0.005
2018-09-12 20:55:39 iteration: 3970 loss: 0.0050 lr: 0.005
2018-09-12 20:56:08 iteration: 3980 loss: 0.0048 lr: 0.005
2018-09-12 20:56:43 iteration: 3990 loss: 0.0050 lr: 0.005
2018-09-12 20:57:20 iteration: 4000 loss: 0.0052 lr: 0.005
2018-09-12 20:57:53 iteration: 4010 loss: 0.0045 lr: 0.005
2018-09-12 20:58:13 iteration: 4020 loss: 0.0045 lr: 0.005
2018-09-12 20:58:43 iteration: 4030 loss: 0.0046 lr: 0.005
2018-09-12 20:59:05 iteration: 4040 loss: 0.0057 lr: 0.005
2018-09-12 20:59:31 iteration: 4050 loss: 0.0052 lr: 0.005
2018-09-12 20:59:55 iteration: 4060 loss: 0.0044 lr: 0.005
2018-09-12 21:00:26 iteration: 4070 loss: 0.0052 lr: 0.005
2018-09-12 21:00:58 iteration: 4080 loss: 0.0053 lr: 0.005
2018-09-12 21:01:26 iteration: 4090 loss: 0.0050 lr: 0.005
2018-09-12 21:01:58 iteration: 4100 loss: 0.0043 lr: 0.005
2018-09-12 21:02:19 iteration: 4110 loss: 0.0044 lr: 0.005
2018-09-12 21:02:41 iteration: 4120 loss: 0.0043 lr: 0.005
2018-09-12 21:03:09 iteration: 4130 loss: 0.0044 lr: 0.005
2018-09-12 21:03:40 iteration: 4140 loss: 0.0043 lr: 0.005
2018-09-12 21:04:15 iteration: 4150 loss: 0.0049 lr: 0.005
2018-09-12 21:04:46 iteration: 4160 loss: 0.0039 lr: 0.005
2018-09-12 21:05:17 iteration: 4170 loss: 0.0049 lr: 0.005
2018-09-12 21:05:44 iteration: 4180 loss: 0.0046 lr: 0.005
2018-09-12 21:06:29 iteration: 4190 loss: 0.0055 lr: 0.005
2018-09-12 21:06:53 iteration: 4200 loss: 0.0051 lr: 0.005
2018-09-12 21:07:22 iteration: 4210 loss: 0.0055 lr: 0.005
2018-09-12 21:07:51 iteration: 4220 loss: 0.0050 lr: 0.005
2018-09-12 21:08:22 iteration: 4230 loss: 0.0049 lr: 0.005
2018-09-12 21:08:57 iteration: 4240 loss: 0.0041 lr: 0.005
2018-09-12 21:09:27 iteration: 4250 loss: 0.0048 lr: 0.005
2018-09-12 21:10:03 iteration: 4260 loss: 0.0051 lr: 0.005
2018-09-12 21:10:27 iteration: 4270 loss: 0.0046 lr: 0.005
2018-09-12 21:10:53 iteration: 4280 loss: 0.0052 lr: 0.005
2018-09-12 21:11:27 iteration: 4290 loss: 0.0052 lr: 0.005
2018-09-12 21:11:49 iteration: 4300 loss: 0.0044 lr: 0.005
2018-09-12 21:12:13 iteration: 4310 loss: 0.0046 lr: 0.005
2018-09-12 21:12:31 iteration: 4320 loss: 0.0045 lr: 0.005
2018-09-12 21:12:56 iteration: 4330 loss: 0.0047 lr: 0.005
2018-09-12 21:13:28 iteration: 4340 loss: 0.0044 lr: 0.005
2018-09-12 21:13:58 iteration: 4350 loss: 0.0046 lr: 0.005
2018-09-12 21:14:30 iteration: 4360 loss: 0.0047 lr: 0.005
2018-09-12 21:15:02 iteration: 4370 loss: 0.0049 lr: 0.005
2018-09-12 21:15:27 iteration: 4380 loss: 0.0045 lr: 0.005
2018-09-12 21:15:54 iteration: 4390 loss: 0.0045 lr: 0.005
2018-09-12 21:16:16 iteration: 4400 loss: 0.0042 lr: 0.005
2018-09-12 21:16:46 iteration: 4410 loss: 0.0041 lr: 0.005
2018-09-12 21:17:19 iteration: 4420 loss: 0.0044 lr: 0.005
2018-09-12 21:17:50 iteration: 4430 loss: 0.0043 lr: 0.005
2018-09-12 21:18:09 iteration: 4440 loss: 0.0054 lr: 0.005
2018-09-12 21:18:39 iteration: 4450 loss: 0.0042 lr: 0.005
2018-09-12 21:19:05 iteration: 4460 loss: 0.0049 lr: 0.005
2018-09-12 21:19:32 iteration: 4470 loss: 0.0044 lr: 0.005
2018-09-12 21:20:01 iteration: 4480 loss: 0.0051 lr: 0.005
2018-09-12 21:20:32 iteration: 4490 loss: 0.0044 lr: 0.005
2018-09-12 21:21:03 iteration: 4500 loss: 0.0044 lr: 0.005
2018-09-12 21:21:32 iteration: 4510 loss: 0.0040 lr: 0.005
2018-09-12 21:21:53 iteration: 4520 loss: 0.0044 lr: 0.005
2018-09-12 21:22:25 iteration: 4530 loss: 0.0045 lr: 0.005
2018-09-12 21:22:49 iteration: 4540 loss: 0.0044 lr: 0.005
2018-09-12 21:23:18 iteration: 4550 loss: 0.0045 lr: 0.005
2018-09-12 21:23:40 iteration: 4560 loss: 0.0050 lr: 0.005
2018-09-12 21:24:02 iteration: 4570 loss: 0.0041 lr: 0.005
2018-09-12 21:24:32 iteration: 4580 loss: 0.0053 lr: 0.005
2018-09-12 21:24:56 iteration: 4590 loss: 0.0048 lr: 0.005
2018-09-12 21:25:23 iteration: 4600 loss: 0.0047 lr: 0.005
2018-09-12 21:25:49 iteration: 4610 loss: 0.0048 lr: 0.005
2018-09-12 21:26:16 iteration: 4620 loss: 0.0042 lr: 0.005
2018-09-12 21:26:47 iteration: 4630 loss: 0.0043 lr: 0.005
2018-09-12 21:27:13 iteration: 4640 loss: 0.0042 lr: 0.005
2018-09-12 21:27:46 iteration: 4650 loss: 0.0037 lr: 0.005
2018-09-12 21:28:21 iteration: 4660 loss: 0.0041 lr: 0.005
2018-09-12 21:28:57 iteration: 4670 loss: 0.0046 lr: 0.005
2018-09-12 21:29:29 iteration: 4680 loss: 0.0046 lr: 0.005
2018-09-12 21:30:03 iteration: 4690 loss: 0.0044 lr: 0.005
2018-09-12 21:30:27 iteration: 4700 loss: 0.0047 lr: 0.005
2018-09-12 21:30:57 iteration: 4710 loss: 0.0045 lr: 0.005
2018-09-12 21:31:27 iteration: 4720 loss: 0.0042 lr: 0.005
2018-09-12 21:31:51 iteration: 4730 loss: 0.0042 lr: 0.005
2018-09-12 21:32:16 iteration: 4740 loss: 0.0045 lr: 0.005
2018-09-12 21:32:41 iteration: 4750 loss: 0.0042 lr: 0.005
2018-09-12 21:33:12 iteration: 4760 loss: 0.0045 lr: 0.005
2018-09-12 21:33:42 iteration: 4770 loss: 0.0043 lr: 0.005
2018-09-12 21:34:17 iteration: 4780 loss: 0.0044 lr: 0.005
2018-09-12 21:34:48 iteration: 4790 loss: 0.0042 lr: 0.005
2018-09-12 21:35:14 iteration: 4800 loss: 0.0045 lr: 0.005
2018-09-12 21:35:44 iteration: 4810 loss: 0.0040 lr: 0.005
2018-09-12 21:36:16 iteration: 4820 loss: 0.0051 lr: 0.005
2018-09-12 21:36:38 iteration: 4830 loss: 0.0046 lr: 0.005
2018-09-12 21:37:09 iteration: 4840 loss: 0.0041 lr: 0.005
2018-09-12 21:37:39 iteration: 4850 loss: 0.0039 lr: 0.005
2018-09-12 21:38:05 iteration: 4860 loss: 0.0049 lr: 0.005
2018-09-12 21:38:33 iteration: 4870 loss: 0.0044 lr: 0.005
2018-09-12 21:39:12 iteration: 4880 loss: 0.0047 lr: 0.005
2018-09-12 21:39:38 iteration: 4890 loss: 0.0043 lr: 0.005
2018-09-12 21:40:07 iteration: 4900 loss: 0.0049 lr: 0.005
2018-09-12 21:40:41 iteration: 4910 loss: 0.0046 lr: 0.005
2018-09-12 21:41:11 iteration: 4920 loss: 0.0043 lr: 0.005
2018-09-12 21:41:38 iteration: 4930 loss: 0.0051 lr: 0.005
2018-09-12 21:42:07 iteration: 4940 loss: 0.0045 lr: 0.005
2018-09-12 21:42:32 iteration: 4950 loss: 0.0038 lr: 0.005
2018-09-12 21:43:11 iteration: 4960 loss: 0.0041 lr: 0.005
2018-09-12 21:43:36 iteration: 4970 loss: 0.0039 lr: 0.005
2018-09-12 21:44:02 iteration: 4980 loss: 0.0038 lr: 0.005
2018-09-12 21:44:22 iteration: 4990 loss: 0.0041 lr: 0.005
2018-09-12 21:44:55 iteration: 5000 loss: 0.0041 lr: 0.005
2018-09-12 21:45:18 iteration: 5010 loss: 0.0040 lr: 0.005
2018-09-12 21:45:49 iteration: 5020 loss: 0.0040 lr: 0.005
2018-09-12 21:46:18 iteration: 5030 loss: 0.0040 lr: 0.005
2018-09-12 21:46:41 iteration: 5040 loss: 0.0044 lr: 0.005
2018-09-12 21:47:08 iteration: 5050 loss: 0.0040 lr: 0.005
2018-09-12 21:47:38 iteration: 5060 loss: 0.0042 lr: 0.005
2018-09-12 21:48:06 iteration: 5070 loss: 0.0043 lr: 0.005
2018-09-12 21:48:23 iteration: 5080 loss: 0.0044 lr: 0.005
2018-09-12 21:48:49 iteration: 5090 loss: 0.0042 lr: 0.005
2018-09-12 21:49:19 iteration: 5100 loss: 0.0051 lr: 0.005
2018-09-12 21:49:56 iteration: 5110 loss: 0.0048 lr: 0.005
2018-09-12 21:50:18 iteration: 5120 loss: 0.0041 lr: 0.005
2018-09-12 21:50:48 iteration: 5130 loss: 0.0042 lr: 0.005
2018-09-12 21:51:23 iteration: 5140 loss: 0.0044 lr: 0.005
2018-09-12 21:51:54 iteration: 5150 loss: 0.0035 lr: 0.005
2018-09-12 21:52:35 iteration: 5160 loss: 0.0039 lr: 0.005
2018-09-12 21:52:56 iteration: 5170 loss: 0.0041 lr: 0.005
2018-09-12 21:53:28 iteration: 5180 loss: 0.0038 lr: 0.005
2018-09-12 21:53:46 iteration: 5190 loss: 0.0045 lr: 0.005
2018-09-12 21:54:12 iteration: 5200 loss: 0.0047 lr: 0.005
2018-09-12 21:54:37 iteration: 5210 loss: 0.0046 lr: 0.005
2018-09-12 21:55:03 iteration: 5220 loss: 0.0052 lr: 0.005
2018-09-12 21:55:37 iteration: 5230 loss: 0.0046 lr: 0.005
2018-09-12 21:56:03 iteration: 5240 loss: 0.0050 lr: 0.005
2018-09-12 21:56:34 iteration: 5250 loss: 0.0044 lr: 0.005
2018-09-12 21:57:06 iteration: 5260 loss: 0.0039 lr: 0.005
2018-09-12 21:57:34 iteration: 5270 loss: 0.0036 lr: 0.005
2018-09-12 21:58:06 iteration: 5280 loss: 0.0042 lr: 0.005
2018-09-12 21:58:43 iteration: 5290 loss: 0.0042 lr: 0.005
2018-09-12 21:59:12 iteration: 5300 loss: 0.0037 lr: 0.005
2018-09-12 21:59:38 iteration: 5310 loss: 0.0035 lr: 0.005
2018-09-12 22:00:08 iteration: 5320 loss: 0.0036 lr: 0.005
2018-09-12 22:00:33 iteration: 5330 loss: 0.0037 lr: 0.005
2018-09-12 22:01:01 iteration: 5340 loss: 0.0039 lr: 0.005
2018-09-12 22:01:28 iteration: 5350 loss: 0.0036 lr: 0.005
2018-09-12 22:01:53 iteration: 5360 loss: 0.0041 lr: 0.005
2018-09-12 22:02:28 iteration: 5370 loss: 0.0036 lr: 0.005
2018-09-12 22:03:06 iteration: 5380 loss: 0.0043 lr: 0.005
2018-09-12 22:03:34 iteration: 5390 loss: 0.0043 lr: 0.005
2018-09-12 22:04:05 iteration: 5400 loss: 0.0037 lr: 0.005
2018-09-12 22:04:36 iteration: 5410 loss: 0.0039 lr: 0.005
2018-09-12 22:04:59 iteration: 5420 loss: 0.0043 lr: 0.005
2018-09-12 22:05:38 iteration: 5430 loss: 0.0038 lr: 0.005
2018-09-12 22:06:08 iteration: 5440 loss: 0.0041 lr: 0.005
2018-09-12 22:06:38 iteration: 5450 loss: 0.0044 lr: 0.005
2018-09-12 22:07:06 iteration: 5460 loss: 0.0042 lr: 0.005
2018-09-12 22:07:37 iteration: 5470 loss: 0.0044 lr: 0.005
2018-09-12 22:08:06 iteration: 5480 loss: 0.0047 lr: 0.005
2018-09-12 22:08:40 iteration: 5490 loss: 0.0045 lr: 0.005
2018-09-12 22:09:18 iteration: 5500 loss: 0.0041 lr: 0.005
2018-09-12 22:09:41 iteration: 5510 loss: 0.0039 lr: 0.005
2018-09-12 22:10:01 iteration: 5520 loss: 0.0045 lr: 0.005
2018-09-12 22:10:26 iteration: 5530 loss: 0.0044 lr: 0.005
2018-09-12 22:11:03 iteration: 5540 loss: 0.0042 lr: 0.005
2018-09-12 22:11:30 iteration: 5550 loss: 0.0038 lr: 0.005
2018-09-12 22:12:01 iteration: 5560 loss: 0.0039 lr: 0.005
2018-09-12 22:12:26 iteration: 5570 loss: 0.0035 lr: 0.005
2018-09-12 22:12:54 iteration: 5580 loss: 0.0042 lr: 0.005
2018-09-12 22:13:19 iteration: 5590 loss: 0.0047 lr: 0.005
2018-09-12 22:13:46 iteration: 5600 loss: 0.0041 lr: 0.005
2018-09-12 22:14:07 iteration: 5610 loss: 0.0038 lr: 0.005
2018-09-12 22:14:38 iteration: 5620 loss: 0.0038 lr: 0.005
2018-09-12 22:15:02 iteration: 5630 loss: 0.0039 lr: 0.005
2018-09-12 22:15:31 iteration: 5640 loss: 0.0045 lr: 0.005
2018-09-12 22:15:54 iteration: 5650 loss: 0.0037 lr: 0.005
2018-09-12 22:16:15 iteration: 5660 loss: 0.0036 lr: 0.005
2018-09-12 22:16:55 iteration: 5670 loss: 0.0038 lr: 0.005
2018-09-12 22:17:20 iteration: 5680 loss: 0.0047 lr: 0.005
2018-09-12 22:17:46 iteration: 5690 loss: 0.0040 lr: 0.005
2018-09-12 22:18:20 iteration: 5700 loss: 0.0048 lr: 0.005
2018-09-12 22:18:51 iteration: 5710 loss: 0.0045 lr: 0.005
2018-09-12 22:19:22 iteration: 5720 loss: 0.0048 lr: 0.005
2018-09-12 22:19:50 iteration: 5730 loss: 0.0038 lr: 0.005
2018-09-12 22:20:22 iteration: 5740 loss: 0.0037 lr: 0.005
2018-09-12 22:20:51 iteration: 5750 loss: 0.0040 lr: 0.005
2018-09-12 22:21:18 iteration: 5760 loss: 0.0037 lr: 0.005
2018-09-12 22:21:51 iteration: 5770 loss: 0.0035 lr: 0.005
2018-09-12 22:22:21 iteration: 5780 loss: 0.0038 lr: 0.005
2018-09-12 22:22:56 iteration: 5790 loss: 0.0039 lr: 0.005
2018-09-12 22:23:29 iteration: 5800 loss: 0.0035 lr: 0.005
2018-09-12 22:24:03 iteration: 5810 loss: 0.0038 lr: 0.005
2018-09-12 22:24:26 iteration: 5820 loss: 0.0040 lr: 0.005
2018-09-12 22:24:54 iteration: 5830 loss: 0.0042 lr: 0.005
2018-09-12 22:25:16 iteration: 5840 loss: 0.0039 lr: 0.005
2018-09-12 22:25:39 iteration: 5850 loss: 0.0040 lr: 0.005
2018-09-12 22:26:14 iteration: 5860 loss: 0.0038 lr: 0.005
2018-09-12 22:26:41 iteration: 5870 loss: 0.0039 lr: 0.005
2018-09-12 22:26:59 iteration: 5880 loss: 0.0039 lr: 0.005
2018-09-12 22:27:30 iteration: 5890 loss: 0.0038 lr: 0.005
2018-09-12 22:27:54 iteration: 5900 loss: 0.0035 lr: 0.005
2018-09-12 22:28:18 iteration: 5910 loss: 0.0040 lr: 0.005
2018-09-12 22:28:48 iteration: 5920 loss: 0.0036 lr: 0.005
2018-09-12 22:29:28 iteration: 5930 loss: 0.0034 lr: 0.005
2018-09-12 22:29:57 iteration: 5940 loss: 0.0034 lr: 0.005
2018-09-12 22:30:22 iteration: 5950 loss: 0.0037 lr: 0.005
2018-09-12 22:30:52 iteration: 5960 loss: 0.0036 lr: 0.005
2018-09-12 22:31:32 iteration: 5970 loss: 0.0048 lr: 0.005
2018-09-12 22:32:05 iteration: 5980 loss: 0.0041 lr: 0.005
2018-09-12 22:32:34 iteration: 5990 loss: 0.0046 lr: 0.005
2018-09-12 22:33:04 iteration: 6000 loss: 0.0041 lr: 0.005
2018-09-12 22:33:31 iteration: 6010 loss: 0.0036 lr: 0.005
2018-09-12 22:34:03 iteration: 6020 loss: 0.0037 lr: 0.005
2018-09-12 22:34:27 iteration: 6030 loss: 0.0031 lr: 0.005
2018-09-12 22:34:58 iteration: 6040 loss: 0.0034 lr: 0.005
2018-09-12 22:35:32 iteration: 6050 loss: 0.0034 lr: 0.005
2018-09-12 22:36:03 iteration: 6060 loss: 0.0038 lr: 0.005
2018-09-12 22:36:23 iteration: 6070 loss: 0.0039 lr: 0.005
2018-09-12 22:36:52 iteration: 6080 loss: 0.0034 lr: 0.005
2018-09-12 22:37:13 iteration: 6090 loss: 0.0040 lr: 0.005
2018-09-12 22:37:39 iteration: 6100 loss: 0.0043 lr: 0.005
2018-09-12 22:38:03 iteration: 6110 loss: 0.0035 lr: 0.005
2018-09-12 22:38:27 iteration: 6120 loss: 0.0034 lr: 0.005
2018-09-12 22:38:54 iteration: 6130 loss: 0.0036 lr: 0.005
2018-09-12 22:39:20 iteration: 6140 loss: 0.0038 lr: 0.005
2018-09-12 22:39:45 iteration: 6150 loss: 0.0036 lr: 0.005
2018-09-12 22:40:05 iteration: 6160 loss: 0.0042 lr: 0.005
2018-09-12 22:40:32 iteration: 6170 loss: 0.0034 lr: 0.005
2018-09-12 22:40:59 iteration: 6180 loss: 0.0045 lr: 0.005
2018-09-12 22:41:25 iteration: 6190 loss: 0.0043 lr: 0.005
2018-09-12 22:41:56 iteration: 6200 loss: 0.0036 lr: 0.005
2018-09-12 22:42:23 iteration: 6210 loss: 0.0040 lr: 0.005
2018-09-12 22:42:52 iteration: 6220 loss: 0.0037 lr: 0.005
2018-09-12 22:43:22 iteration: 6230 loss: 0.0037 lr: 0.005
2018-09-12 22:43:48 iteration: 6240 loss: 0.0034 lr: 0.005
2018-09-12 22:44:12 iteration: 6250 loss: 0.0031 lr: 0.005
2018-09-12 22:44:39 iteration: 6260 loss: 0.0036 lr: 0.005
2018-09-12 22:45:08 iteration: 6270 loss: 0.0036 lr: 0.005
2018-09-12 22:45:27 iteration: 6280 loss: 0.0039 lr: 0.005
2018-09-12 22:45:57 iteration: 6290 loss: 0.0041 lr: 0.005
2018-09-12 22:46:35 iteration: 6300 loss: 0.0032 lr: 0.005
2018-09-12 22:47:06 iteration: 6310 loss: 0.0035 lr: 0.005
2018-09-12 22:47:33 iteration: 6320 loss: 0.0047 lr: 0.005
2018-09-12 22:48:08 iteration: 6330 loss: 0.0036 lr: 0.005
2018-09-12 22:48:26 iteration: 6340 loss: 0.0045 lr: 0.005
2018-09-12 22:48:54 iteration: 6350 loss: 0.0039 lr: 0.005
2018-09-12 22:49:24 iteration: 6360 loss: 0.0035 lr: 0.005
2018-09-12 22:49:49 iteration: 6370 loss: 0.0043 lr: 0.005
2018-09-12 22:50:19 iteration: 6380 loss: 0.0038 lr: 0.005
2018-09-12 22:50:38 iteration: 6390 loss: 0.0043 lr: 0.005
2018-09-12 22:51:14 iteration: 6400 loss: 0.0037 lr: 0.005
2018-09-12 22:51:42 iteration: 6410 loss: 0.0044 lr: 0.005
2018-09-12 22:52:06 iteration: 6420 loss: 0.0039 lr: 0.005
2018-09-12 22:52:37 iteration: 6430 loss: 0.0035 lr: 0.005
2018-09-12 22:53:02 iteration: 6440 loss: 0.0042 lr: 0.005
2018-09-12 22:53:33 iteration: 6450 loss: 0.0038 lr: 0.005
2018-09-12 22:53:59 iteration: 6460 loss: 0.0041 lr: 0.005
2018-09-12 22:54:32 iteration: 6470 loss: 0.0034 lr: 0.005
2018-09-12 22:55:08 iteration: 6480 loss: 0.0037 lr: 0.005
2018-09-12 22:55:33 iteration: 6490 loss: 0.0042 lr: 0.005
2018-09-12 22:55:59 iteration: 6500 loss: 0.0045 lr: 0.005
2018-09-12 22:56:34 iteration: 6510 loss: 0.0036 lr: 0.005
2018-09-12 22:56:59 iteration: 6520 loss: 0.0035 lr: 0.005
2018-09-12 22:57:25 iteration: 6530 loss: 0.0035 lr: 0.005
2018-09-12 22:57:48 iteration: 6540 loss: 0.0039 lr: 0.005
2018-09-12 22:58:13 iteration: 6550 loss: 0.0033 lr: 0.005
2018-09-12 22:58:44 iteration: 6560 loss: 0.0036 lr: 0.005
2018-09-12 22:59:12 iteration: 6570 loss: 0.0041 lr: 0.005
2018-09-12 22:59:55 iteration: 6580 loss: 0.0036 lr: 0.005
2018-09-12 23:00:23 iteration: 6590 loss: 0.0040 lr: 0.005
2018-09-12 23:00:54 iteration: 6600 loss: 0.0038 lr: 0.005
2018-09-12 23:01:19 iteration: 6610 loss: 0.0044 lr: 0.005
2018-09-12 23:01:46 iteration: 6620 loss: 0.0048 lr: 0.005
2018-09-12 23:02:16 iteration: 6630 loss: 0.0033 lr: 0.005
2018-09-12 23:02:48 iteration: 6640 loss: 0.0037 lr: 0.005
2018-09-12 23:03:18 iteration: 6650 loss: 0.0036 lr: 0.005
2018-09-12 23:03:50 iteration: 6660 loss: 0.0033 lr: 0.005
2018-09-12 23:04:22 iteration: 6670 loss: 0.0044 lr: 0.005
2018-09-12 23:04:46 iteration: 6680 loss: 0.0038 lr: 0.005
2018-09-12 23:05:17 iteration: 6690 loss: 0.0037 lr: 0.005
2018-09-12 23:05:40 iteration: 6700 loss: 0.0038 lr: 0.005
2018-09-12 23:06:04 iteration: 6710 loss: 0.0036 lr: 0.005
2018-09-12 23:06:23 iteration: 6720 loss: 0.0038 lr: 0.005
2018-09-12 23:06:49 iteration: 6730 loss: 0.0036 lr: 0.005
2018-09-12 23:07:17 iteration: 6740 loss: 0.0037 lr: 0.005
2018-09-12 23:07:51 iteration: 6750 loss: 0.0039 lr: 0.005
2018-09-12 23:08:16 iteration: 6760 loss: 0.0037 lr: 0.005
2018-09-12 23:08:53 iteration: 6770 loss: 0.0035 lr: 0.005
2018-09-12 23:09:21 iteration: 6780 loss: 0.0033 lr: 0.005
2018-09-12 23:09:52 iteration: 6790 loss: 0.0038 lr: 0.005
2018-09-12 23:10:24 iteration: 6800 loss: 0.0038 lr: 0.005
2018-09-12 23:10:58 iteration: 6810 loss: 0.0038 lr: 0.005
2018-09-12 23:11:27 iteration: 6820 loss: 0.0031 lr: 0.005
2018-09-12 23:11:59 iteration: 6830 loss: 0.0040 lr: 0.005
2018-09-12 23:12:33 iteration: 6840 loss: 0.0039 lr: 0.005
2018-09-12 23:13:04 iteration: 6850 loss: 0.0039 lr: 0.005
2018-09-12 23:13:35 iteration: 6860 loss: 0.0031 lr: 0.005
2018-09-12 23:13:57 iteration: 6870 loss: 0.0040 lr: 0.005
2018-09-12 23:14:30 iteration: 6880 loss: 0.0030 lr: 0.005
2018-09-12 23:14:57 iteration: 6890 loss: 0.0036 lr: 0.005
2018-09-12 23:15:21 iteration: 6900 loss: 0.0038 lr: 0.005
2018-09-12 23:15:51 iteration: 6910 loss: 0.0031 lr: 0.005
2018-09-12 23:16:16 iteration: 6920 loss: 0.0033 lr: 0.005
2018-09-12 23:16:45 iteration: 6930 loss: 0.0034 lr: 0.005
2018-09-12 23:17:12 iteration: 6940 loss: 0.0031 lr: 0.005
2018-09-12 23:17:34 iteration: 6950 loss: 0.0035 lr: 0.005
2018-09-12 23:18:07 iteration: 6960 loss: 0.0043 lr: 0.005
2018-09-12 23:18:39 iteration: 6970 loss: 0.0039 lr: 0.005
2018-09-12 23:19:11 iteration: 6980 loss: 0.0033 lr: 0.005
2018-09-12 23:19:45 iteration: 6990 loss: 0.0034 lr: 0.005
2018-09-12 23:20:24 iteration: 7000 loss: 0.0038 lr: 0.005
2018-09-12 23:20:53 iteration: 7010 loss: 0.0037 lr: 0.005
2018-09-12 23:21:21 iteration: 7020 loss: 0.0041 lr: 0.005
2018-09-12 23:21:51 iteration: 7030 loss: 0.0033 lr: 0.005
2018-09-12 23:22:15 iteration: 7040 loss: 0.0034 lr: 0.005
2018-09-12 23:22:37 iteration: 7050 loss: 0.0039 lr: 0.005
2018-09-12 23:23:04 iteration: 7060 loss: 0.0032 lr: 0.005
2018-09-12 23:23:36 iteration: 7070 loss: 0.0036 lr: 0.005
2018-09-12 23:24:15 iteration: 7080 loss: 0.0033 lr: 0.005
2018-09-12 23:24:46 iteration: 7090 loss: 0.0032 lr: 0.005
2018-09-12 23:25:18 iteration: 7100 loss: 0.0035 lr: 0.005
2018-09-12 23:25:49 iteration: 7110 loss: 0.0036 lr: 0.005
2018-09-12 23:26:17 iteration: 7120 loss: 0.0041 lr: 0.005
2018-09-12 23:26:45 iteration: 7130 loss: 0.0038 lr: 0.005
2018-09-12 23:27:12 iteration: 7140 loss: 0.0038 lr: 0.005
2018-09-12 23:27:38 iteration: 7150 loss: 0.0043 lr: 0.005
2018-09-12 23:28:05 iteration: 7160 loss: 0.0036 lr: 0.005
2018-09-12 23:28:34 iteration: 7170 loss: 0.0038 lr: 0.005
2018-09-12 23:28:57 iteration: 7180 loss: 0.0037 lr: 0.005
2018-09-12 23:29:26 iteration: 7190 loss: 0.0034 lr: 0.005
2018-09-12 23:29:42 iteration: 7200 loss: 0.0037 lr: 0.005
2018-09-12 23:30:13 iteration: 7210 loss: 0.0036 lr: 0.005
2018-09-12 23:30:44 iteration: 7220 loss: 0.0036 lr: 0.005
2018-09-12 23:31:10 iteration: 7230 loss: 0.0034 lr: 0.005
2018-09-12 23:31:36 iteration: 7240 loss: 0.0040 lr: 0.005
2018-09-12 23:32:02 iteration: 7250 loss: 0.0039 lr: 0.005
2018-09-12 23:32:27 iteration: 7260 loss: 0.0035 lr: 0.005
2018-09-12 23:32:56 iteration: 7270 loss: 0.0035 lr: 0.005
2018-09-12 23:33:21 iteration: 7280 loss: 0.0046 lr: 0.005
2018-09-12 23:33:56 iteration: 7290 loss: 0.0040 lr: 0.005
2018-09-12 23:34:32 iteration: 7300 loss: 0.0034 lr: 0.005
2018-09-12 23:35:02 iteration: 7310 loss: 0.0036 lr: 0.005
2018-09-12 23:35:34 iteration: 7320 loss: 0.0037 lr: 0.005
2018-09-12 23:36:09 iteration: 7330 loss: 0.0045 lr: 0.005
2018-09-12 23:36:35 iteration: 7340 loss: 0.0042 lr: 0.005
2018-09-12 23:37:09 iteration: 7350 loss: 0.0039 lr: 0.005
2018-09-12 23:37:35 iteration: 7360 loss: 0.0030 lr: 0.005
2018-09-12 23:38:04 iteration: 7370 loss: 0.0036 lr: 0.005
2018-09-12 23:38:33 iteration: 7380 loss: 0.0031 lr: 0.005
2018-09-12 23:38:54 iteration: 7390 loss: 0.0036 lr: 0.005
2018-09-12 23:39:20 iteration: 7400 loss: 0.0032 lr: 0.005
2018-09-12 23:39:42 iteration: 7410 loss: 0.0035 lr: 0.005
2018-09-12 23:40:11 iteration: 7420 loss: 0.0033 lr: 0.005
2018-09-12 23:40:49 iteration: 7430 loss: 0.0037 lr: 0.005
2018-09-12 23:41:15 iteration: 7440 loss: 0.0036 lr: 0.005
2018-09-12 23:41:45 iteration: 7450 loss: 0.0040 lr: 0.005
2018-09-12 23:42:18 iteration: 7460 loss: 0.0032 lr: 0.005
2018-09-12 23:42:44 iteration: 7470 loss: 0.0033 lr: 0.005
2018-09-12 23:43:12 iteration: 7480 loss: 0.0035 lr: 0.005
2018-09-12 23:43:41 iteration: 7490 loss: 0.0036 lr: 0.005
2018-09-12 23:44:08 iteration: 7500 loss: 0.0037 lr: 0.005
2018-09-12 23:44:33 iteration: 7510 loss: 0.0035 lr: 0.005
2018-09-12 23:44:58 iteration: 7520 loss: 0.0033 lr: 0.005
2018-09-12 23:45:26 iteration: 7530 loss: 0.0034 lr: 0.005
2018-09-12 23:45:52 iteration: 7540 loss: 0.0030 lr: 0.005
2018-09-12 23:46:23 iteration: 7550 loss: 0.0028 lr: 0.005
2018-09-12 23:46:48 iteration: 7560 loss: 0.0033 lr: 0.005
2018-09-12 23:47:13 iteration: 7570 loss: 0.0034 lr: 0.005
2018-09-12 23:47:45 iteration: 7580 loss: 0.0034 lr: 0.005
2018-09-12 23:48:14 iteration: 7590 loss: 0.0037 lr: 0.005
2018-09-12 23:48:41 iteration: 7600 loss: 0.0033 lr: 0.005
2018-09-12 23:49:21 iteration: 7610 loss: 0.0035 lr: 0.005
2018-09-12 23:49:44 iteration: 7620 loss: 0.0036 lr: 0.005
2018-09-12 23:50:01 iteration: 7630 loss: 0.0036 lr: 0.005
2018-09-12 23:50:28 iteration: 7640 loss: 0.0031 lr: 0.005
2018-09-12 23:51:01 iteration: 7650 loss: 0.0038 lr: 0.005
2018-09-12 23:51:26 iteration: 7660 loss: 0.0040 lr: 0.005
2018-09-12 23:51:53 iteration: 7670 loss: 0.0036 lr: 0.005
2018-09-12 23:52:16 iteration: 7680 loss: 0.0040 lr: 0.005
2018-09-12 23:52:49 iteration: 7690 loss: 0.0035 lr: 0.005
2018-09-12 23:53:19 iteration: 7700 loss: 0.0037 lr: 0.005
2018-09-12 23:53:52 iteration: 7710 loss: 0.0034 lr: 0.005
2018-09-12 23:54:26 iteration: 7720 loss: 0.0036 lr: 0.005
2018-09-12 23:54:51 iteration: 7730 loss: 0.0034 lr: 0.005
2018-09-12 23:55:20 iteration: 7740 loss: 0.0034 lr: 0.005
2018-09-12 23:55:53 iteration: 7750 loss: 0.0038 lr: 0.005
2018-09-12 23:56:17 iteration: 7760 loss: 0.0030 lr: 0.005
2018-09-12 23:56:49 iteration: 7770 loss: 0.0030 lr: 0.005
2018-09-12 23:57:14 iteration: 7780 loss: 0.0034 lr: 0.005
2018-09-12 23:57:46 iteration: 7790 loss: 0.0035 lr: 0.005
2018-09-12 23:58:08 iteration: 7800 loss: 0.0035 lr: 0.005
2018-09-12 23:58:35 iteration: 7810 loss: 0.0033 lr: 0.005
2018-09-12 23:59:14 iteration: 7820 loss: 0.0032 lr: 0.005
2018-09-13 00:00:00 iteration: 7830 loss: 0.0032 lr: 0.005
2018-09-13 00:00:27 iteration: 7840 loss: 0.0033 lr: 0.005
2018-09-13 00:00:49 iteration: 7850 loss: 0.0032 lr: 0.005
2018-09-13 00:01:16 iteration: 7860 loss: 0.0033 lr: 0.005
2018-09-13 00:01:52 iteration: 7870 loss: 0.0032 lr: 0.005
2018-09-13 00:02:19 iteration: 7880 loss: 0.0033 lr: 0.005
2018-09-13 00:02:45 iteration: 7890 loss: 0.0039 lr: 0.005
2018-09-13 00:03:19 iteration: 7900 loss: 0.0034 lr: 0.005
2018-09-13 00:03:47 iteration: 7910 loss: 0.0035 lr: 0.005
2018-09-13 00:04:21 iteration: 7920 loss: 0.0031 lr: 0.005
2018-09-13 00:04:49 iteration: 7930 loss: 0.0032 lr: 0.005
2018-09-13 00:05:20 iteration: 7940 loss: 0.0033 lr: 0.005
2018-09-13 00:05:41 iteration: 7950 loss: 0.0033 lr: 0.005
2018-09-13 00:06:10 iteration: 7960 loss: 0.0036 lr: 0.005
2018-09-13 00:06:33 iteration: 7970 loss: 0.0031 lr: 0.005
2018-09-13 00:07:00 iteration: 7980 loss: 0.0035 lr: 0.005
2018-09-13 00:07:20 iteration: 7990 loss: 0.0034 lr: 0.005
2018-09-13 00:07:48 iteration: 8000 loss: 0.0034 lr: 0.005
2018-09-13 00:08:20 iteration: 8010 loss: 0.0030 lr: 0.005
2018-09-13 00:08:46 iteration: 8020 loss: 0.0036 lr: 0.005
2018-09-13 00:09:16 iteration: 8030 loss: 0.0036 lr: 0.005
2018-09-13 00:09:55 iteration: 8040 loss: 0.0032 lr: 0.005
2018-09-13 00:10:24 iteration: 8050 loss: 0.0032 lr: 0.005
2018-09-13 00:10:53 iteration: 8060 loss: 0.0031 lr: 0.005
2018-09-13 00:11:21 iteration: 8070 loss: 0.0030 lr: 0.005
2018-09-13 00:11:45 iteration: 8080 loss: 0.0034 lr: 0.005
2018-09-13 00:12:10 iteration: 8090 loss: 0.0032 lr: 0.005
2018-09-13 00:12:37 iteration: 8100 loss: 0.0033 lr: 0.005
2018-09-13 00:13:07 iteration: 8110 loss: 0.0033 lr: 0.005
2018-09-13 00:13:39 iteration: 8120 loss: 0.0036 lr: 0.005
2018-09-13 00:14:04 iteration: 8130 loss: 0.0028 lr: 0.005
2018-09-13 00:14:35 iteration: 8140 loss: 0.0037 lr: 0.005
2018-09-13 00:15:15 iteration: 8150 loss: 0.0034 lr: 0.005
2018-09-13 00:15:39 iteration: 8160 loss: 0.0037 lr: 0.005
2018-09-13 00:16:18 iteration: 8170 loss: 0.0028 lr: 0.005
2018-09-13 00:16:48 iteration: 8180 loss: 0.0035 lr: 0.005
2018-09-13 00:17:17 iteration: 8190 loss: 0.0029 lr: 0.005
2018-09-13 00:17:45 iteration: 8200 loss: 0.0034 lr: 0.005
2018-09-13 00:18:22 iteration: 8210 loss: 0.0033 lr: 0.005
2018-09-13 00:18:38 iteration: 8220 loss: 0.0035 lr: 0.005
2018-09-13 00:19:00 iteration: 8230 loss: 0.0036 lr: 0.005
2018-09-13 00:19:40 iteration: 8240 loss: 0.0032 lr: 0.005
2018-09-13 00:20:06 iteration: 8250 loss: 0.0038 lr: 0.005
2018-09-13 00:20:34 iteration: 8260 loss: 0.0033 lr: 0.005
2018-09-13 00:20:57 iteration: 8270 loss: 0.0034 lr: 0.005
2018-09-13 00:21:21 iteration: 8280 loss: 0.0040 lr: 0.005
2018-09-13 00:21:50 iteration: 8290 loss: 0.0027 lr: 0.005
2018-09-13 00:22:27 iteration: 8300 loss: 0.0029 lr: 0.005
2018-09-13 00:22:56 iteration: 8310 loss: 0.0036 lr: 0.005
2018-09-13 00:23:24 iteration: 8320 loss: 0.0029 lr: 0.005
2018-09-13 00:23:46 iteration: 8330 loss: 0.0033 lr: 0.005
2018-09-13 00:24:07 iteration: 8340 loss: 0.0034 lr: 0.005
2018-09-13 00:24:38 iteration: 8350 loss: 0.0031 lr: 0.005
2018-09-13 00:25:14 iteration: 8360 loss: 0.0032 lr: 0.005
2018-09-13 00:25:39 iteration: 8370 loss: 0.0029 lr: 0.005
2018-09-13 00:26:06 iteration: 8380 loss: 0.0037 lr: 0.005
2018-09-13 00:26:29 iteration: 8390 loss: 0.0035 lr: 0.005
2018-09-13 00:26:58 iteration: 8400 loss: 0.0036 lr: 0.005
2018-09-13 00:27:27 iteration: 8410 loss: 0.0035 lr: 0.005
2018-09-13 00:28:03 iteration: 8420 loss: 0.0032 lr: 0.005
2018-09-13 00:28:31 iteration: 8430 loss: 0.0034 lr: 0.005
2018-09-13 00:28:56 iteration: 8440 loss: 0.0031 lr: 0.005
2018-09-13 00:29:19 iteration: 8450 loss: 0.0031 lr: 0.005
2018-09-13 00:29:49 iteration: 8460 loss: 0.0031 lr: 0.005
2018-09-13 00:30:15 iteration: 8470 loss: 0.0030 lr: 0.005
2018-09-13 00:30:36 iteration: 8480 loss: 0.0030 lr: 0.005
2018-09-13 00:31:03 iteration: 8490 loss: 0.0031 lr: 0.005
2018-09-13 00:31:30 iteration: 8500 loss: 0.0033 lr: 0.005
2018-09-13 00:31:58 iteration: 8510 loss: 0.0034 lr: 0.005
2018-09-13 00:32:35 iteration: 8520 loss: 0.0031 lr: 0.005
2018-09-13 00:33:01 iteration: 8530 loss: 0.0038 lr: 0.005
2018-09-13 00:33:26 iteration: 8540 loss: 0.0034 lr: 0.005
2018-09-13 00:33:54 iteration: 8550 loss: 0.0031 lr: 0.005
2018-09-13 00:34:21 iteration: 8560 loss: 0.0029 lr: 0.005
2018-09-13 00:34:53 iteration: 8570 loss: 0.0029 lr: 0.005
2018-09-13 00:35:24 iteration: 8580 loss: 0.0033 lr: 0.005
2018-09-13 00:35:55 iteration: 8590 loss: 0.0026 lr: 0.005
2018-09-13 00:36:26 iteration: 8600 loss: 0.0035 lr: 0.005
2018-09-13 00:36:55 iteration: 8610 loss: 0.0036 lr: 0.005
2018-09-13 00:37:18 iteration: 8620 loss: 0.0035 lr: 0.005
2018-09-13 00:37:48 iteration: 8630 loss: 0.0031 lr: 0.005
2018-09-13 00:38:19 iteration: 8640 loss: 0.0040 lr: 0.005
2018-09-13 00:38:44 iteration: 8650 loss: 0.0029 lr: 0.005
2018-09-13 00:39:11 iteration: 8660 loss: 0.0040 lr: 0.005
2018-09-13 00:39:45 iteration: 8670 loss: 0.0030 lr: 0.005
2018-09-13 00:40:11 iteration: 8680 loss: 0.0035 lr: 0.005
2018-09-13 00:40:38 iteration: 8690 loss: 0.0033 lr: 0.005
2018-09-13 00:41:09 iteration: 8700 loss: 0.0031 lr: 0.005
2018-09-13 00:41:36 iteration: 8710 loss: 0.0031 lr: 0.005
2018-09-13 00:42:10 iteration: 8720 loss: 0.0030 lr: 0.005
2018-09-13 00:42:33 iteration: 8730 loss: 0.0033 lr: 0.005
2018-09-13 00:42:53 iteration: 8740 loss: 0.0038 lr: 0.005
2018-09-13 00:43:16 iteration: 8750 loss: 0.0037 lr: 0.005
2018-09-13 00:43:32 iteration: 8760 loss: 0.0041 lr: 0.005
2018-09-13 00:43:58 iteration: 8770 loss: 0.0032 lr: 0.005
2018-09-13 00:44:28 iteration: 8780 loss: 0.0033 lr: 0.005
2018-09-13 00:45:01 iteration: 8790 loss: 0.0033 lr: 0.005
2018-09-13 00:45:35 iteration: 8800 loss: 0.0028 lr: 0.005
2018-09-13 00:46:04 iteration: 8810 loss: 0.0035 lr: 0.005
2018-09-13 00:46:32 iteration: 8820 loss: 0.0025 lr: 0.005
2018-09-13 00:46:54 iteration: 8830 loss: 0.0035 lr: 0.005
2018-09-13 00:47:24 iteration: 8840 loss: 0.0036 lr: 0.005
2018-09-13 00:47:53 iteration: 8850 loss: 0.0029 lr: 0.005
2018-09-13 00:48:19 iteration: 8860 loss: 0.0030 lr: 0.005
2018-09-13 00:48:47 iteration: 8870 loss: 0.0034 lr: 0.005
2018-09-13 00:49:18 iteration: 8880 loss: 0.0033 lr: 0.005
2018-09-13 00:49:52 iteration: 8890 loss: 0.0031 lr: 0.005
2018-09-13 00:50:20 iteration: 8900 loss: 0.0031 lr: 0.005
2018-09-13 00:50:42 iteration: 8910 loss: 0.0031 lr: 0.005
2018-09-13 00:51:05 iteration: 8920 loss: 0.0032 lr: 0.005
2018-09-13 00:51:32 iteration: 8930 loss: 0.0034 lr: 0.005
2018-09-13 00:51:59 iteration: 8940 loss: 0.0030 lr: 0.005
2018-09-13 00:52:24 iteration: 8950 loss: 0.0027 lr: 0.005
2018-09-13 00:52:54 iteration: 8960 loss: 0.0032 lr: 0.005
2018-09-13 00:53:19 iteration: 8970 loss: 0.0033 lr: 0.005
2018-09-13 00:53:45 iteration: 8980 loss: 0.0033 lr: 0.005
2018-09-13 00:54:10 iteration: 8990 loss: 0.0031 lr: 0.005
2018-09-13 00:54:36 iteration: 9000 loss: 0.0032 lr: 0.005
2018-09-13 00:55:01 iteration: 9010 loss: 0.0033 lr: 0.005
2018-09-13 00:55:30 iteration: 9020 loss: 0.0034 lr: 0.005
2018-09-13 00:55:58 iteration: 9030 loss: 0.0036 lr: 0.005
2018-09-13 00:56:24 iteration: 9040 loss: 0.0033 lr: 0.005
2018-09-13 00:56:58 iteration: 9050 loss: 0.0030 lr: 0.005
2018-09-13 00:57:36 iteration: 9060 loss: 0.0028 lr: 0.005
2018-09-13 00:58:07 iteration: 9070 loss: 0.0030 lr: 0.005
2018-09-13 00:58:42 iteration: 9080 loss: 0.0037 lr: 0.005
2018-09-13 00:59:07 iteration: 9090 loss: 0.0028 lr: 0.005
2018-09-13 00:59:36 iteration: 9100 loss: 0.0030 lr: 0.005
2018-09-13 01:00:01 iteration: 9110 loss: 0.0036 lr: 0.005
2018-09-13 01:00:25 iteration: 9120 loss: 0.0032 lr: 0.005
2018-09-13 01:00:51 iteration: 9130 loss: 0.0037 lr: 0.005
2018-09-13 01:01:17 iteration: 9140 loss: 0.0032 lr: 0.005
2018-09-13 01:01:45 iteration: 9150 loss: 0.0028 lr: 0.005
2018-09-13 01:02:18 iteration: 9160 loss: 0.0028 lr: 0.005
2018-09-13 01:02:44 iteration: 9170 loss: 0.0032 lr: 0.005
2018-09-13 01:03:09 iteration: 9180 loss: 0.0029 lr: 0.005
2018-09-13 01:03:39 iteration: 9190 loss: 0.0033 lr: 0.005
2018-09-13 01:04:02 iteration: 9200 loss: 0.0028 lr: 0.005
2018-09-13 01:04:36 iteration: 9210 loss: 0.0030 lr: 0.005
2018-09-13 01:05:00 iteration: 9220 loss: 0.0028 lr: 0.005
2018-09-13 01:05:34 iteration: 9230 loss: 0.0031 lr: 0.005
2018-09-13 01:06:02 iteration: 9240 loss: 0.0033 lr: 0.005
2018-09-13 01:06:23 iteration: 9250 loss: 0.0032 lr: 0.005
2018-09-13 01:06:53 iteration: 9260 loss: 0.0025 lr: 0.005
2018-09-13 01:07:27 iteration: 9270 loss: 0.0038 lr: 0.005
2018-09-13 01:07:54 iteration: 9280 loss: 0.0030 lr: 0.005
2018-09-13 01:08:24 iteration: 9290 loss: 0.0031 lr: 0.005
2018-09-13 01:08:47 iteration: 9300 loss: 0.0031 lr: 0.005
2018-09-13 01:09:14 iteration: 9310 loss: 0.0033 lr: 0.005
2018-09-13 01:09:44 iteration: 9320 loss: 0.0032 lr: 0.005
2018-09-13 01:10:12 iteration: 9330 loss: 0.0032 lr: 0.005
2018-09-13 01:10:38 iteration: 9340 loss: 0.0030 lr: 0.005
2018-09-13 01:11:04 iteration: 9350 loss: 0.0025 lr: 0.005
2018-09-13 01:11:25 iteration: 9360 loss: 0.0032 lr: 0.005
2018-09-13 01:11:54 iteration: 9370 loss: 0.0027 lr: 0.005
2018-09-13 01:12:26 iteration: 9380 loss: 0.0029 lr: 0.005
2018-09-13 01:12:57 iteration: 9390 loss: 0.0027 lr: 0.005
2018-09-13 01:13:38 iteration: 9400 loss: 0.0032 lr: 0.005
2018-09-13 01:14:01 iteration: 9410 loss: 0.0034 lr: 0.005
2018-09-13 01:14:29 iteration: 9420 loss: 0.0032 lr: 0.005
2018-09-13 01:14:49 iteration: 9430 loss: 0.0028 lr: 0.005
2018-09-13 01:15:13 iteration: 9440 loss: 0.0037 lr: 0.005
2018-09-13 01:15:38 iteration: 9450 loss: 0.0033 lr: 0.005
2018-09-13 01:16:05 iteration: 9460 loss: 0.0032 lr: 0.005
2018-09-13 01:16:36 iteration: 9470 loss: 0.0039 lr: 0.005
2018-09-13 01:17:00 iteration: 9480 loss: 0.0035 lr: 0.005
2018-09-13 01:17:22 iteration: 9490 loss: 0.0035 lr: 0.005
2018-09-13 01:17:43 iteration: 9500 loss: 0.0034 lr: 0.005
2018-09-13 01:18:10 iteration: 9510 loss: 0.0034 lr: 0.005
2018-09-13 01:18:35 iteration: 9520 loss: 0.0035 lr: 0.005
2018-09-13 01:19:03 iteration: 9530 loss: 0.0032 lr: 0.005
2018-09-13 01:19:31 iteration: 9540 loss: 0.0029 lr: 0.005
2018-09-13 01:20:02 iteration: 9550 loss: 0.0028 lr: 0.005
2018-09-13 01:20:29 iteration: 9560 loss: 0.0030 lr: 0.005
2018-09-13 01:21:04 iteration: 9570 loss: 0.0027 lr: 0.005
2018-09-13 01:21:25 iteration: 9580 loss: 0.0032 lr: 0.005
2018-09-13 01:21:52 iteration: 9590 loss: 0.0032 lr: 0.005
2018-09-13 01:22:16 iteration: 9600 loss: 0.0029 lr: 0.005
2018-09-13 01:22:50 iteration: 9610 loss: 0.0026 lr: 0.005
2018-09-13 01:23:15 iteration: 9620 loss: 0.0027 lr: 0.005
2018-09-13 01:23:52 iteration: 9630 loss: 0.0029 lr: 0.005
2018-09-13 01:24:17 iteration: 9640 loss: 0.0030 lr: 0.005
2018-09-13 01:24:45 iteration: 9650 loss: 0.0027 lr: 0.005
2018-09-13 01:25:10 iteration: 9660 loss: 0.0036 lr: 0.005
2018-09-13 01:25:38 iteration: 9670 loss: 0.0035 lr: 0.005
2018-09-13 01:26:10 iteration: 9680 loss: 0.0036 lr: 0.005
2018-09-13 01:26:34 iteration: 9690 loss: 0.0032 lr: 0.005
2018-09-13 01:27:00 iteration: 9700 loss: 0.0031 lr: 0.005
2018-09-13 01:27:30 iteration: 9710 loss: 0.0034 lr: 0.005
2018-09-13 01:28:00 iteration: 9720 loss: 0.0030 lr: 0.005
2018-09-13 01:28:25 iteration: 9730 loss: 0.0032 lr: 0.005
2018-09-13 01:28:57 iteration: 9740 loss: 0.0028 lr: 0.005
2018-09-13 01:29:23 iteration: 9750 loss: 0.0027 lr: 0.005
2018-09-13 01:29:56 iteration: 9760 loss: 0.0027 lr: 0.005
2018-09-13 01:30:28 iteration: 9770 loss: 0.0031 lr: 0.005
2018-09-13 01:30:53 iteration: 9780 loss: 0.0029 lr: 0.005
2018-09-13 01:31:15 iteration: 9790 loss: 0.0030 lr: 0.005
2018-09-13 01:31:40 iteration: 9800 loss: 0.0034 lr: 0.005
2018-09-13 01:32:11 iteration: 9810 loss: 0.0030 lr: 0.005
2018-09-13 01:32:37 iteration: 9820 loss: 0.0032 lr: 0.005
2018-09-13 01:33:02 iteration: 9830 loss: 0.0036 lr: 0.005
2018-09-13 01:33:21 iteration: 9840 loss: 0.0037 lr: 0.005
2018-09-13 01:33:45 iteration: 9850 loss: 0.0033 lr: 0.005
2018-09-13 01:34:18 iteration: 9860 loss: 0.0033 lr: 0.005
2018-09-13 01:34:42 iteration: 9870 loss: 0.0032 lr: 0.005
2018-09-13 01:35:03 iteration: 9880 loss: 0.0029 lr: 0.005
2018-09-13 01:35:24 iteration: 9890 loss: 0.0035 lr: 0.005
2018-09-13 01:36:01 iteration: 9900 loss: 0.0032 lr: 0.005
2018-09-13 01:36:20 iteration: 9910 loss: 0.0027 lr: 0.005
2018-09-13 01:36:42 iteration: 9920 loss: 0.0030 lr: 0.005
2018-09-13 01:37:18 iteration: 9930 loss: 0.0035 lr: 0.005
2018-09-13 01:37:53 iteration: 9940 loss: 0.0030 lr: 0.005
2018-09-13 01:38:26 iteration: 9950 loss: 0.0031 lr: 0.005
2018-09-13 01:39:03 iteration: 9960 loss: 0.0031 lr: 0.005
2018-09-13 01:39:27 iteration: 9970 loss: 0.0035 lr: 0.005
2018-09-13 01:39:50 iteration: 9980 loss: 0.0033 lr: 0.005
2018-09-13 01:40:25 iteration: 9990 loss: 0.0031 lr: 0.005
2018-09-13 01:40:59 iteration: 10000 loss: 0.0032 lr: 0.005
2018-09-13 01:41:33 iteration: 10010 loss: 0.0043 lr: 0.02
2018-09-13 01:42:01 iteration: 10020 loss: 0.0059 lr: 0.02
2018-09-13 01:42:27 iteration: 10030 loss: 0.0071 lr: 0.02
2018-09-13 01:43:01 iteration: 10040 loss: 0.0063 lr: 0.02
2018-09-13 01:43:31 iteration: 10050 loss: 0.0064 lr: 0.02
2018-09-13 01:43:56 iteration: 10060 loss: 0.0057 lr: 0.02
2018-09-13 01:44:26 iteration: 10070 loss: 0.0070 lr: 0.02
2018-09-13 01:44:49 iteration: 10080 loss: 0.0057 lr: 0.02
2018-09-13 01:45:17 iteration: 10090 loss: 0.0062 lr: 0.02
2018-09-13 01:45:55 iteration: 10100 loss: 0.0082 lr: 0.02
2018-09-13 01:46:28 iteration: 10110 loss: 0.0079 lr: 0.02
2018-09-13 01:46:58 iteration: 10120 loss: 0.0090 lr: 0.02
2018-09-13 01:47:26 iteration: 10130 loss: 0.0101 lr: 0.02
2018-09-13 01:48:08 iteration: 10140 loss: 0.0092 lr: 0.02
2018-09-13 01:48:36 iteration: 10150 loss: 0.0071 lr: 0.02
2018-09-13 01:49:06 iteration: 10160 loss: 0.0073 lr: 0.02
2018-09-13 01:49:29 iteration: 10170 loss: 0.0070 lr: 0.02
2018-09-13 01:49:50 iteration: 10180 loss: 0.0066 lr: 0.02
2018-09-13 01:50:28 iteration: 10190 loss: 0.0068 lr: 0.02
2018-09-13 01:50:58 iteration: 10200 loss: 0.0064 lr: 0.02
2018-09-13 01:51:23 iteration: 10210 loss: 0.0066 lr: 0.02
2018-09-13 01:51:49 iteration: 10220 loss: 0.0061 lr: 0.02
2018-09-13 01:52:16 iteration: 10230 loss: 0.0064 lr: 0.02
2018-09-13 01:52:45 iteration: 10240 loss: 0.0072 lr: 0.02
2018-09-13 01:53:11 iteration: 10250 loss: 0.0068 lr: 0.02
2018-09-13 01:53:40 iteration: 10260 loss: 0.0080 lr: 0.02
2018-09-13 01:54:01 iteration: 10270 loss: 0.0063 lr: 0.02
2018-09-13 01:54:27 iteration: 10280 loss: 0.0067 lr: 0.02
2018-09-13 01:54:57 iteration: 10290 loss: 0.0087 lr: 0.02
2018-09-13 01:55:24 iteration: 10300 loss: 0.0073 lr: 0.02
2018-09-13 01:55:49 iteration: 10310 loss: 0.0060 lr: 0.02
2018-09-13 01:56:21 iteration: 10320 loss: 0.0061 lr: 0.02
2018-09-13 01:56:44 iteration: 10330 loss: 0.0062 lr: 0.02
2018-09-13 01:57:15 iteration: 10340 loss: 0.0059 lr: 0.02
2018-09-13 01:57:41 iteration: 10350 loss: 0.0061 lr: 0.02
2018-09-13 01:58:11 iteration: 10360 loss: 0.0057 lr: 0.02
2018-09-13 01:58:31 iteration: 10370 loss: 0.0050 lr: 0.02
2018-09-13 01:58:59 iteration: 10380 loss: 0.0060 lr: 0.02
2018-09-13 01:59:32 iteration: 10390 loss: 0.0057 lr: 0.02
2018-09-13 02:00:06 iteration: 10400 loss: 0.0048 lr: 0.02
2018-09-13 02:00:32 iteration: 10410 loss: 0.0051 lr: 0.02
2018-09-13 02:01:03 iteration: 10420 loss: 0.0049 lr: 0.02
2018-09-13 02:01:32 iteration: 10430 loss: 0.0063 lr: 0.02
2018-09-13 02:02:06 iteration: 10440 loss: 0.0057 lr: 0.02
2018-09-13 02:02:33 iteration: 10450 loss: 0.0045 lr: 0.02
2018-09-13 02:03:02 iteration: 10460 loss: 0.0058 lr: 0.02
2018-09-13 02:03:27 iteration: 10470 loss: 0.0053 lr: 0.02
2018-09-13 02:04:01 iteration: 10480 loss: 0.0070 lr: 0.02
2018-09-13 02:04:31 iteration: 10490 loss: 0.0064 lr: 0.02
2018-09-13 02:05:09 iteration: 10500 loss: 0.0065 lr: 0.02
2018-09-13 02:05:40 iteration: 10510 loss: 0.0057 lr: 0.02
2018-09-13 02:06:05 iteration: 10520 loss: 0.0054 lr: 0.02
2018-09-13 02:06:28 iteration: 10530 loss: 0.0057 lr: 0.02
2018-09-13 02:06:54 iteration: 10540 loss: 0.0065 lr: 0.02
2018-09-13 02:07:12 iteration: 10550 loss: 0.0050 lr: 0.02
2018-09-13 02:07:49 iteration: 10560 loss: 0.0067 lr: 0.02
2018-09-13 02:08:22 iteration: 10570 loss: 0.0055 lr: 0.02
2018-09-13 02:08:46 iteration: 10580 loss: 0.0051 lr: 0.02
2018-09-13 02:09:08 iteration: 10590 loss: 0.0054 lr: 0.02
2018-09-13 02:09:32 iteration: 10600 loss: 0.0059 lr: 0.02
2018-09-13 02:09:58 iteration: 10610 loss: 0.0050 lr: 0.02
2018-09-13 02:10:29 iteration: 10620 loss: 0.0054 lr: 0.02
2018-09-13 02:10:57 iteration: 10630 loss: 0.0045 lr: 0.02
2018-09-13 02:11:23 iteration: 10640 loss: 0.0046 lr: 0.02
2018-09-13 02:11:50 iteration: 10650 loss: 0.0051 lr: 0.02
2018-09-13 02:12:15 iteration: 10660 loss: 0.0044 lr: 0.02
2018-09-13 02:12:39 iteration: 10670 loss: 0.0047 lr: 0.02
2018-09-13 02:13:16 iteration: 10680 loss: 0.0053 lr: 0.02
2018-09-13 02:13:59 iteration: 10690 loss: 0.0052 lr: 0.02
2018-09-13 02:14:19 iteration: 10700 loss: 0.0046 lr: 0.02
2018-09-13 02:14:53 iteration: 10710 loss: 0.0054 lr: 0.02
2018-09-13 02:15:17 iteration: 10720 loss: 0.0041 lr: 0.02
2018-09-13 02:15:44 iteration: 10730 loss: 0.0054 lr: 0.02
2018-09-13 02:16:15 iteration: 10740 loss: 0.0055 lr: 0.02
2018-09-13 02:16:41 iteration: 10750 loss: 0.0052 lr: 0.02
2018-09-13 02:17:17 iteration: 10760 loss: 0.0051 lr: 0.02
2018-09-13 02:17:39 iteration: 10770 loss: 0.0054 lr: 0.02
2018-09-13 02:18:01 iteration: 10780 loss: 0.0048 lr: 0.02
2018-09-13 02:18:33 iteration: 10790 loss: 0.0046 lr: 0.02
2018-09-13 02:19:01 iteration: 10800 loss: 0.0051 lr: 0.02
2018-09-13 02:19:29 iteration: 10810 loss: 0.0053 lr: 0.02
2018-09-13 02:19:52 iteration: 10820 loss: 0.0048 lr: 0.02
2018-09-13 02:20:19 iteration: 10830 loss: 0.0047 lr: 0.02
2018-09-13 02:20:46 iteration: 10840 loss: 0.0045 lr: 0.02
2018-09-13 02:21:19 iteration: 10850 loss: 0.0053 lr: 0.02
2018-09-13 02:21:51 iteration: 10860 loss: 0.0055 lr: 0.02
2018-09-13 02:22:13 iteration: 10870 loss: 0.0049 lr: 0.02
2018-09-13 02:22:36 iteration: 10880 loss: 0.0050 lr: 0.02
2018-09-13 02:23:17 iteration: 10890 loss: 0.0055 lr: 0.02
2018-09-13 02:23:46 iteration: 10900 loss: 0.0052 lr: 0.02
2018-09-13 02:24:08 iteration: 10910 loss: 0.0049 lr: 0.02
2018-09-13 02:24:41 iteration: 10920 loss: 0.0058 lr: 0.02
2018-09-13 02:25:12 iteration: 10930 loss: 0.0045 lr: 0.02
2018-09-13 02:25:43 iteration: 10940 loss: 0.0045 lr: 0.02
2018-09-13 02:26:05 iteration: 10950 loss: 0.0058 lr: 0.02
2018-09-13 02:26:28 iteration: 10960 loss: 0.0056 lr: 0.02
2018-09-13 02:27:01 iteration: 10970 loss: 0.0051 lr: 0.02
2018-09-13 02:27:26 iteration: 10980 loss: 0.0057 lr: 0.02
2018-09-13 02:27:57 iteration: 10990 loss: 0.0066 lr: 0.02
2018-09-13 02:28:33 iteration: 11000 loss: 0.0053 lr: 0.02
2018-09-13 02:29:14 iteration: 11010 loss: 0.0052 lr: 0.02
2018-09-13 02:29:43 iteration: 11020 loss: 0.0053 lr: 0.02
2018-09-13 02:30:04 iteration: 11030 loss: 0.0050 lr: 0.02
2018-09-13 02:30:40 iteration: 11040 loss: 0.0048 lr: 0.02
2018-09-13 02:31:00 iteration: 11050 loss: 0.0047 lr: 0.02
2018-09-13 02:31:27 iteration: 11060 loss: 0.0043 lr: 0.02
2018-09-13 02:31:58 iteration: 11070 loss: 0.0055 lr: 0.02
2018-09-13 02:32:21 iteration: 11080 loss: 0.0044 lr: 0.02
2018-09-13 02:32:52 iteration: 11090 loss: 0.0049 lr: 0.02
2018-09-13 02:33:11 iteration: 11100 loss: 0.0046 lr: 0.02
2018-09-13 02:33:43 iteration: 11110 loss: 0.0051 lr: 0.02
2018-09-13 02:34:05 iteration: 11120 loss: 0.0045 lr: 0.02
2018-09-13 02:34:31 iteration: 11130 loss: 0.0050 lr: 0.02
2018-09-13 02:35:00 iteration: 11140 loss: 0.0036 lr: 0.02
2018-09-13 02:35:41 iteration: 11150 loss: 0.0042 lr: 0.02
2018-09-13 02:36:13 iteration: 11160 loss: 0.0040 lr: 0.02
2018-09-13 02:36:39 iteration: 11170 loss: 0.0046 lr: 0.02
2018-09-13 02:37:01 iteration: 11180 loss: 0.0042 lr: 0.02
2018-09-13 02:37:27 iteration: 11190 loss: 0.0041 lr: 0.02
2018-09-13 02:37:50 iteration: 11200 loss: 0.0051 lr: 0.02
2018-09-13 02:38:24 iteration: 11210 loss: 0.0062 lr: 0.02
2018-09-13 02:38:52 iteration: 11220 loss: 0.0046 lr: 0.02
2018-09-13 02:39:15 iteration: 11230 loss: 0.0044 lr: 0.02
2018-09-13 02:39:43 iteration: 11240 loss: 0.0051 lr: 0.02
2018-09-13 02:40:14 iteration: 11250 loss: 0.0047 lr: 0.02
2018-09-13 02:40:46 iteration: 11260 loss: 0.0053 lr: 0.02
2018-09-13 02:41:19 iteration: 11270 loss: 0.0052 lr: 0.02
2018-09-13 02:41:49 iteration: 11280 loss: 0.0041 lr: 0.02
2018-09-13 02:42:20 iteration: 11290 loss: 0.0042 lr: 0.02
2018-09-13 02:42:57 iteration: 11300 loss: 0.0042 lr: 0.02
2018-09-13 02:43:28 iteration: 11310 loss: 0.0049 lr: 0.02
2018-09-13 02:44:00 iteration: 11320 loss: 0.0052 lr: 0.02
2018-09-13 02:44:22 iteration: 11330 loss: 0.0051 lr: 0.02
2018-09-13 02:44:46 iteration: 11340 loss: 0.0044 lr: 0.02
2018-09-13 02:45:11 iteration: 11350 loss: 0.0048 lr: 0.02
2018-09-13 02:45:59 iteration: 11360 loss: 0.0054 lr: 0.02
2018-09-13 02:46:29 iteration: 11370 loss: 0.0046 lr: 0.02
2018-09-13 02:47:01 iteration: 11380 loss: 0.0046 lr: 0.02
2018-09-13 02:47:35 iteration: 11390 loss: 0.0042 lr: 0.02
2018-09-13 02:48:01 iteration: 11400 loss: 0.0038 lr: 0.02
2018-09-13 02:48:29 iteration: 11410 loss: 0.0048 lr: 0.02
2018-09-13 02:48:48 iteration: 11420 loss: 0.0032 lr: 0.02
2018-09-13 02:49:13 iteration: 11430 loss: 0.0037 lr: 0.02
2018-09-13 02:49:43 iteration: 11440 loss: 0.0035 lr: 0.02
2018-09-13 02:50:04 iteration: 11450 loss: 0.0044 lr: 0.02
2018-09-13 02:50:39 iteration: 11460 loss: 0.0039 lr: 0.02
2018-09-13 02:51:01 iteration: 11470 loss: 0.0048 lr: 0.02
2018-09-13 02:51:26 iteration: 11480 loss: 0.0037 lr: 0.02
2018-09-13 02:51:48 iteration: 11490 loss: 0.0039 lr: 0.02
2018-09-13 02:52:16 iteration: 11500 loss: 0.0044 lr: 0.02
2018-09-13 02:52:49 iteration: 11510 loss: 0.0039 lr: 0.02
2018-09-13 02:53:18 iteration: 11520 loss: 0.0038 lr: 0.02
2018-09-13 02:53:43 iteration: 11530 loss: 0.0038 lr: 0.02
2018-09-13 02:54:07 iteration: 11540 loss: 0.0038 lr: 0.02
2018-09-13 02:54:35 iteration: 11550 loss: 0.0039 lr: 0.02
2018-09-13 02:54:58 iteration: 11560 loss: 0.0047 lr: 0.02
2018-09-13 02:55:23 iteration: 11570 loss: 0.0039 lr: 0.02
2018-09-13 02:55:45 iteration: 11580 loss: 0.0040 lr: 0.02
2018-09-13 02:56:11 iteration: 11590 loss: 0.0042 lr: 0.02
2018-09-13 02:56:41 iteration: 11600 loss: 0.0039 lr: 0.02
2018-09-13 02:57:07 iteration: 11610 loss: 0.0039 lr: 0.02
2018-09-13 02:57:29 iteration: 11620 loss: 0.0040 lr: 0.02
2018-09-13 02:58:02 iteration: 11630 loss: 0.0039 lr: 0.02
2018-09-13 02:58:38 iteration: 11640 loss: 0.0040 lr: 0.02
2018-09-13 02:59:05 iteration: 11650 loss: 0.0049 lr: 0.02
2018-09-13 02:59:27 iteration: 11660 loss: 0.0041 lr: 0.02
2018-09-13 02:59:58 iteration: 11670 loss: 0.0043 lr: 0.02
2018-09-13 03:00:24 iteration: 11680 loss: 0.0036 lr: 0.02
2018-09-13 03:00:54 iteration: 11690 loss: 0.0044 lr: 0.02
2018-09-13 03:01:19 iteration: 11700 loss: 0.0040 lr: 0.02
2018-09-13 03:01:44 iteration: 11710 loss: 0.0042 lr: 0.02
2018-09-13 03:02:26 iteration: 11720 loss: 0.0043 lr: 0.02
2018-09-13 03:02:58 iteration: 11730 loss: 0.0049 lr: 0.02
2018-09-13 03:03:35 iteration: 11740 loss: 0.0047 lr: 0.02
2018-09-13 03:04:08 iteration: 11750 loss: 0.0043 lr: 0.02
2018-09-13 03:04:34 iteration: 11760 loss: 0.0036 lr: 0.02
2018-09-13 03:05:02 iteration: 11770 loss: 0.0038 lr: 0.02
2018-09-13 03:05:26 iteration: 11780 loss: 0.0039 lr: 0.02
2018-09-13 03:05:58 iteration: 11790 loss: 0.0044 lr: 0.02
2018-09-13 03:06:31 iteration: 11800 loss: 0.0050 lr: 0.02
2018-09-13 03:07:01 iteration: 11810 loss: 0.0043 lr: 0.02
2018-09-13 03:07:21 iteration: 11820 loss: 0.0040 lr: 0.02
2018-09-13 03:07:58 iteration: 11830 loss: 0.0037 lr: 0.02
2018-09-13 03:08:28 iteration: 11840 loss: 0.0039 lr: 0.02
2018-09-13 03:08:56 iteration: 11850 loss: 0.0037 lr: 0.02
2018-09-13 03:09:23 iteration: 11860 loss: 0.0031 lr: 0.02
2018-09-13 03:09:52 iteration: 11870 loss: 0.0038 lr: 0.02
2018-09-13 03:10:17 iteration: 11880 loss: 0.0034 lr: 0.02
2018-09-13 03:10:45 iteration: 11890 loss: 0.0036 lr: 0.02
2018-09-13 03:11:05 iteration: 11900 loss: 0.0046 lr: 0.02
2018-09-13 03:11:34 iteration: 11910 loss: 0.0047 lr: 0.02
2018-09-13 03:11:59 iteration: 11920 loss: 0.0043 lr: 0.02
2018-09-13 03:12:26 iteration: 11930 loss: 0.0039 lr: 0.02
2018-09-13 03:12:50 iteration: 11940 loss: 0.0042 lr: 0.02
2018-09-13 03:13:21 iteration: 11950 loss: 0.0039 lr: 0.02
2018-09-13 03:14:03 iteration: 11960 loss: 0.0042 lr: 0.02
2018-09-13 03:14:33 iteration: 11970 loss: 0.0040 lr: 0.02
2018-09-13 03:15:06 iteration: 11980 loss: 0.0048 lr: 0.02
2018-09-13 03:15:24 iteration: 11990 loss: 0.0044 lr: 0.02
2018-09-13 03:16:00 iteration: 12000 loss: 0.0042 lr: 0.02
2018-09-13 03:16:26 iteration: 12010 loss: 0.0045 lr: 0.02
2018-09-13 03:16:47 iteration: 12020 loss: 0.0044 lr: 0.02
2018-09-13 03:17:04 iteration: 12030 loss: 0.0043 lr: 0.02
2018-09-13 03:17:32 iteration: 12040 loss: 0.0033 lr: 0.02
2018-09-13 03:17:58 iteration: 12050 loss: 0.0038 lr: 0.02
2018-09-13 03:18:32 iteration: 12060 loss: 0.0041 lr: 0.02
2018-09-13 03:19:01 iteration: 12070 loss: 0.0046 lr: 0.02
2018-09-13 03:19:30 iteration: 12080 loss: 0.0039 lr: 0.02
2018-09-13 03:20:06 iteration: 12090 loss: 0.0037 lr: 0.02
2018-09-13 03:20:38 iteration: 12100 loss: 0.0042 lr: 0.02
2018-09-13 03:20:59 iteration: 12110 loss: 0.0038 lr: 0.02
2018-09-13 03:21:29 iteration: 12120 loss: 0.0039 lr: 0.02
2018-09-13 03:21:58 iteration: 12130 loss: 0.0034 lr: 0.02
2018-09-13 03:22:24 iteration: 12140 loss: 0.0051 lr: 0.02
2018-09-13 03:22:56 iteration: 12150 loss: 0.0035 lr: 0.02
2018-09-13 03:23:30 iteration: 12160 loss: 0.0040 lr: 0.02
2018-09-13 03:24:03 iteration: 12170 loss: 0.0033 lr: 0.02
2018-09-13 03:24:31 iteration: 12180 loss: 0.0036 lr: 0.02
2018-09-13 03:24:57 iteration: 12190 loss: 0.0035 lr: 0.02
2018-09-13 03:25:28 iteration: 12200 loss: 0.0032 lr: 0.02
2018-09-13 03:25:52 iteration: 12210 loss: 0.0038 lr: 0.02
2018-09-13 03:26:24 iteration: 12220 loss: 0.0038 lr: 0.02
2018-09-13 03:26:53 iteration: 12230 loss: 0.0036 lr: 0.02
2018-09-13 03:27:25 iteration: 12240 loss: 0.0033 lr: 0.02
2018-09-13 03:27:52 iteration: 12250 loss: 0.0033 lr: 0.02
2018-09-13 03:28:11 iteration: 12260 loss: 0.0036 lr: 0.02
2018-09-13 03:28:51 iteration: 12270 loss: 0.0036 lr: 0.02
2018-09-13 03:29:21 iteration: 12280 loss: 0.0036 lr: 0.02
2018-09-13 03:30:01 iteration: 12290 loss: 0.0033 lr: 0.02
2018-09-13 03:30:27 iteration: 12300 loss: 0.0031 lr: 0.02
2018-09-13 03:30:53 iteration: 12310 loss: 0.0036 lr: 0.02
2018-09-13 03:31:19 iteration: 12320 loss: 0.0032 lr: 0.02
